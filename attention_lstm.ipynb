{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjPTaRB4mpCd"
   },
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9IS9B9-yUU5"
   },
   "source": [
    "## Setup PyTorch\n",
    "All files are stored at /content/csc421/a3/ folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axbuunY8UdTB"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-6MQhMOlHXD",
    "outputId": "d3cbae92-dd1f-4892-9096-a1ec660964da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-9.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 27.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.9.24)\n",
      "Installing collected packages: pillow\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 4.0.0\n",
      "    Uninstalling Pillow-4.0.0:\n",
      "      Successfully uninstalled Pillow-4.0.0\n",
      "Successfully installed pillow-9.3.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "PIL"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting Pillow==4.0.0\n",
      "  Using cached Pillow-4.0.0-cp37-cp37m-linux_x86_64.whl\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.7/dist-packages (from Pillow==4.0.0) (0.46)\n",
      "Installing collected packages: Pillow\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 9.3.0\n",
      "    Uninstalling Pillow-9.3.0:\n",
      "      Successfully uninstalled Pillow-9.3.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.13.1+cu113 requires pillow!=8.3.*,>=5.3.0, but you have pillow 4.0.0 which is incompatible.\n",
      "scikit-image 0.18.3 requires pillow!=7.1.0,!=7.1.1,>=4.3.0, but you have pillow 4.0.0 which is incompatible.\n",
      "fastai 2.7.10 requires pillow>6.0.0, but you have pillow 4.0.0 which is incompatible.\n",
      "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 4.0.0 which is incompatible.\u001b[0m\n",
      "Successfully installed Pillow-4.0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "PIL"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/content/csc421/a3/content/csc421/a3\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# Setup python environment and change the current working directory\n",
    "######################################################################\n",
    "!pip install torch torchvision\n",
    "!pip install Pillow==4.0.0\n",
    "%mkdir -p ./content/csc421/a3/\n",
    "%cd ./content/csc421/a3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DaTdRNuUra7"
   },
   "source": [
    "# Helper code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BIpGwANoQOg"
   },
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-UJHBYZkh7f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import argparse\n",
    "import pickle as pkl\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import tarfile\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "\n",
    "def get_file(fname,\n",
    "             origin,\n",
    "             untar=False,\n",
    "             extract=False,\n",
    "             archive_format='auto',\n",
    "             cache_dir='data'):\n",
    "    datadir = os.path.join(cache_dir)\n",
    "    if not os.path.exists(datadir):\n",
    "        os.makedirs(datadir)\n",
    "\n",
    "    if untar:\n",
    "        untar_fpath = os.path.join(datadir, fname)\n",
    "        fpath = untar_fpath + '.tar.gz'\n",
    "    else:\n",
    "        fpath = os.path.join(datadir, fname)\n",
    "    \n",
    "    print(fpath)\n",
    "    if not os.path.exists(fpath):\n",
    "        print('Downloading data from', origin)\n",
    "\n",
    "        error_msg = 'URL fetch failure on {}: {} -- {}'\n",
    "        try:\n",
    "            try:\n",
    "                urlretrieve(origin, fpath)\n",
    "            except URLError as e:\n",
    "                raise Exception(error_msg.format(origin, e.errno, e.reason))\n",
    "            except HTTPError as e:\n",
    "                raise Exception(error_msg.format(origin, e.code, e.msg))\n",
    "        except (Exception, KeyboardInterrupt) as e:\n",
    "            if os.path.exists(fpath):\n",
    "                os.remove(fpath)\n",
    "            raise\n",
    "\n",
    "    if untar:\n",
    "        if not os.path.exists(untar_fpath):\n",
    "            print('Extracting file.')\n",
    "            with tarfile.open(fpath) as archive:\n",
    "                archive.extractall(datadir)\n",
    "        return untar_fpath\n",
    "\n",
    "    if extract:\n",
    "        _extract_archive(fpath, datadir, archive_format)\n",
    "\n",
    "    return fpath\n",
    "\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "        \n",
    "def to_var(tensor, cuda):\n",
    "    \"\"\"Wraps a Tensor in a Variable, optionally placing it on the GPU.\n",
    "\n",
    "        Arguments:\n",
    "            tensor: A Tensor object.\n",
    "            cuda: A boolean flag indicating whether to use the GPU.\n",
    "\n",
    "        Returns:\n",
    "            A Variable object, on the GPU if cuda==True.\n",
    "    \"\"\"\n",
    "    if cuda:\n",
    "        return Variable(tensor.cuda())\n",
    "    else:\n",
    "        return Variable(tensor)\n",
    "\n",
    "\n",
    "def create_dir_if_not_exists(directory):\n",
    "    \"\"\"Creates a directory if it doesn't already exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "def save_loss_plot(train_losses, val_losses, opts):\n",
    "    \"\"\"Saves a plot of the training and validation loss curves.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(train_losses)), train_losses)\n",
    "    plt.plot(range(len(val_losses)), val_losses)\n",
    "    plt.title('BS={}, nhid={}'.format(opts.batch_size, opts.hidden_size), fontsize=20)\n",
    "    plt.xlabel('Epochs', fontsize=16)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(opts.checkpoint_path, 'loss_plot.pdf'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def save_loss_comparison_lstm(l1, l2, o1, o2, fn, s=500):\n",
    "    \"\"\"Plot comparison of training and val loss curves from LSTM runs.\n",
    "    \n",
    "    Arguments:\n",
    "        l1: Tuple of lists containing training / val losses for model 1.\n",
    "        l2: Tuple of lists containing training / val losses for model 2.\n",
    "        o1: Options for model 1.\n",
    "        o2: Options for model 2.\n",
    "        fn: Output file name.\n",
    "        s: Number of training iterations to average over.\n",
    "    \"\"\"\n",
    "    mean_l1 = [np.mean(l1[0][i*s:(i+1)*s]) for i in range(len(l1[0]) // s)]\n",
    "    mean_l2 = [np.mean(l2[0][i*s:(i+1)*s]) for i in range(len(l2[0]) // s)]\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "    ax[0].plot(range(len(mean_l1)), mean_l1, label='ds=' + o1.data_file_name)\n",
    "    ax[0].plot(range(len(mean_l2)), mean_l2, label='ds=' + o2.data_file_name)\n",
    "    ax[0].title.set_text('Train Loss | LSTM Hidden Size = {}'.format(o2.hidden_size))\n",
    "\n",
    "    # Validation losses are assumed to be by epoch\n",
    "    ax[1].plot(range(len(l1[1])), l1[1], label='ds=' + o1.data_file_name)\n",
    "    ax[1].plot(range(len(l2[1])), l2[1], label='ds=' + o2.data_file_name)\n",
    "    ax[1].title.set_text('Val Loss | LSTM Hidden Size = {}'.format(o2.hidden_size))\n",
    "\n",
    "    ax[0].set_xlabel(\"Iterations (x{})\".format(s), fontsize=10)\n",
    "    ax[0].set_ylabel(\"Loss\", fontsize=10)\n",
    "    ax[1].set_xlabel(\"Epochs\", fontsize=10)\n",
    "    ax[1].set_ylabel(\"Loss\", fontsize=10)\n",
    "    ax[0].legend(loc=\"upper right\")\n",
    "    ax[1].legend(loc=\"upper right\")\n",
    "\n",
    "    fig.suptitle('LSTM Performance by Dataset', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(top=0.85)\n",
    "    plt.legend()\n",
    "    plt.savefig('./loss_plot_{}.pdf'.format(fn))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def save_loss_comparison_by_dataset(l1, l2, l3, l4, o1, o2, o3, o4, fn, s=500):\n",
    "    \"\"\"Plot comparison of training and validation loss curves from all four\n",
    "    runs in Part 3, comparing by dataset while holding hidden size constant.\n",
    "\n",
    "    Models within each pair (l1, l2) and (l3, l4) have the same hidden sizes.\n",
    "\n",
    "    Arguments:\n",
    "        l1: Tuple of lists containing training / val losses for model 1.\n",
    "        l2: Tuple of lists containing training / val losses for model 2.\n",
    "        l3: Tuple of lists containing training / val losses for model 3.\n",
    "        l4: Tuple of lists containing training / val losses for model 4.\n",
    "        o1: Options for model 1.\n",
    "        o2: Options for model 2.\n",
    "        o3: Options for model 3.\n",
    "        o4: Options for model 4.\n",
    "        fn: Output file name.\n",
    "        s: Number of training iterations to average over.\n",
    "    \"\"\"\n",
    "    mean_l1 = [np.mean(l1[0][i*s:(i+1)*s]) for i in range(len(l1[0]) // s)]\n",
    "    mean_l2 = [np.mean(l2[0][i*s:(i+1)*s]) for i in range(len(l2[0]) // s)]\n",
    "    mean_l3 = [np.mean(l3[0][i*s:(i+1)*s]) for i in range(len(l3[0]) // s)]\n",
    "    mean_l4 = [np.mean(l4[0][i*s:(i+1)*s]) for i in range(len(l4[0]) // s)]\n",
    "\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "    ax[0][0].plot(range(len(mean_l1)), mean_l1, label='ds=' + o1.data_file_name)\n",
    "    ax[0][0].plot(range(len(mean_l2)), mean_l2, label='ds=' + o2.data_file_name)\n",
    "    ax[0][0].title.set_text('Train Loss | Model Hidden Size = {}'.format(o1.hidden_size))\n",
    "\n",
    "    # Validation losses are assumed to be by epoch\n",
    "    ax[0][1].plot(range(len(l1[1])), l1[1], label='ds=' + o1.data_file_name)\n",
    "    ax[0][1].plot(range(len(l2[1])), l2[1], label='ds=' + o2.data_file_name)\n",
    "    ax[0][1].title.set_text('Val Loss | Model Hidden Size = {}'.format(o1.hidden_size))\n",
    "\n",
    "    ax[1][0].plot(range(len(mean_l3)), mean_l3, label='ds=' + o3.data_file_name)\n",
    "    ax[1][0].plot(range(len(mean_l4)), mean_l4, label='ds=' + o4.data_file_name)\n",
    "    ax[1][0].title.set_text('Train Loss | Model Hidden Size = {}'.format(o3.hidden_size))\n",
    "\n",
    "    ax[1][1].plot(range(len(l3[1])), l3[1], label='ds=' + o3.data_file_name)\n",
    "    ax[1][1].plot(range(len(l4[1])), l4[1], label='ds=' + o4.data_file_name)\n",
    "    ax[1][1].title.set_text('Val Loss | Model Hidden Size = {}'.format(o4.hidden_size))\n",
    "\n",
    "    for i in range(2):\n",
    "        ax[i][0].set_xlabel(\"Iterations (x{})\".format(s), fontsize=10)\n",
    "        ax[i][0].set_ylabel(\"Loss\", fontsize=10)\n",
    "        ax[i][1].set_xlabel(\"Epochs\", fontsize=10)\n",
    "        ax[i][1].set_ylabel(\"Loss\", fontsize=10)\n",
    "        ax[i][0].legend(loc=\"upper right\")\n",
    "        ax[i][1].legend(loc=\"upper right\")\n",
    "\n",
    "    fig.suptitle(\"Performance by Dataset Size\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(top=0.9)\n",
    "    plt.legend()\n",
    "    plt.savefig('./loss_plot_{}.pdf'.format(fn))\n",
    "    plt.close()\n",
    "\n",
    "def save_loss_comparison_by_hidden(l1, l2, l3, l4, o1, o2, o3, o4, fn, s=500):\n",
    "    \"\"\"Plot comparison of training and validation loss curves from all four\n",
    "    runs in Part 3, comparing by hidden size while holding dataset constant.\n",
    "\n",
    "    Models within each pair (l1, l3) and (l2, l4) have the same dataset.\n",
    "\n",
    "    Arguments:\n",
    "        l1: Tuple of lists containing training / val losses for model 1.\n",
    "        l2: Tuple of lists containing training / val losses for model 2.\n",
    "        l3: Tuple of lists containing training / val losses for model 3.\n",
    "        l4: Tuple of lists containing training / val losses for model 4.\n",
    "        o1: Options for model 1.\n",
    "        o2: Options for model 2.\n",
    "        o3: Options for model 3.\n",
    "        o4: Options for model 4.\n",
    "        fn: Output file name.\n",
    "        s: Number of training iterations to average over.\n",
    "    \"\"\"\n",
    "    mean_l1 = [np.mean(l1[0][i*s:(i+1)*s]) for i in range(len(l1[0]) // s)]\n",
    "    mean_l2 = [np.mean(l2[0][i*s:(i+1)*s]) for i in range(len(l2[0]) // s)]\n",
    "    mean_l3 = [np.mean(l3[0][i*s:(i+1)*s]) for i in range(len(l3[0]) // s)]\n",
    "    mean_l4 = [np.mean(l4[0][i*s:(i+1)*s]) for i in range(len(l4[0]) // s)]\n",
    "\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "    ax[0][0].plot(range(len(mean_l1)), mean_l1, label='hid_size=' + str(o1.hidden_size))\n",
    "    ax[0][0].plot(range(len(mean_l3)), mean_l3, label='hid_size=' + str(o3.hidden_size))\n",
    "    ax[0][0].title.set_text('Train Loss | Dataset = ' + o1.data_file_name)\n",
    "\n",
    "    # Validation losses are assumed to be by epoch\n",
    "    ax[0][1].plot(range(len(l1[1])), l1[1], label='hid_size=' + str(o1.hidden_size))\n",
    "    ax[0][1].plot(range(len(l3[1])), l3[1], label='hid_size=' + str(o3.hidden_size))\n",
    "    ax[0][1].title.set_text('Val Loss | Dataset = ' + o1.data_file_name)\n",
    "\n",
    "    ax[1][0].plot(range(len(mean_l2)), mean_l2, label='hid_size=' + str(o2.hidden_size))\n",
    "    ax[1][0].plot(range(len(mean_l4)), mean_l4, label='hid_size=' + str(o4.hidden_size))\n",
    "    ax[1][0].title.set_text('Train Loss | Dataset = ' + o3.data_file_name)\n",
    "\n",
    "    ax[1][1].plot(range(len(l2[1])), l2[1], label='hid_size=' + str(o2.hidden_size))\n",
    "    ax[1][1].plot(range(len(l4[1])), l4[1], label='hid_size=' + str(o4.hidden_size))\n",
    "    ax[1][1].title.set_text('Val Loss | Dataset = ' + o4.data_file_name)\n",
    "\n",
    "    for i in range(2):\n",
    "        ax[i][0].set_xlabel(\"Iterations (x{})\".format(s), fontsize=10)\n",
    "        ax[i][0].set_ylabel(\"Loss\", fontsize=10)\n",
    "        ax[i][1].set_xlabel(\"Epochs\", fontsize=10)\n",
    "        ax[i][1].set_ylabel(\"Loss\", fontsize=10)\n",
    "        ax[i][0].legend(loc=\"upper right\")\n",
    "        ax[i][1].legend(loc=\"upper right\")\n",
    "\n",
    "    fig.suptitle(\"Performance by Hidden State Size\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(top=0.9)\n",
    "    plt.legend()\n",
    "    plt.savefig('./loss_plot_{}.pdf'.format(fn))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def checkpoint(encoder, decoder, idx_dict, opts):\n",
    "    \"\"\"Saves the current encoder and decoder models, along with idx_dict, which\n",
    "    contains the char_to_index and index_to_char mappings, and the start_token\n",
    "    and end_token values.\n",
    "    \"\"\"\n",
    "    with open(os.path.join(opts.checkpoint_path, 'encoder.pt'), 'wb') as f:\n",
    "        torch.save(encoder, f)\n",
    "\n",
    "    with open(os.path.join(opts.checkpoint_path, 'decoder.pt'), 'wb') as f:\n",
    "        torch.save(decoder, f)\n",
    "\n",
    "    with open(os.path.join(opts.checkpoint_path, 'idx_dict.pkl'), 'wb') as f:\n",
    "        pkl.dump(idx_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbvpn4MaV0I1"
   },
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVT4TNTOV3Eg"
   },
   "outputs": [],
   "source": [
    "def read_lines(filename):\n",
    "    \"\"\"Read a file and split it into lines.\n",
    "    \"\"\"\n",
    "    lines = open(filename).read().strip().lower().split('\\n')\n",
    "    return lines\n",
    "\n",
    "\n",
    "def read_pairs(filename):\n",
    "    \"\"\"Reads lines that consist of two words, separated by a space.\n",
    "\n",
    "    Returns:\n",
    "        source_words: A list of the first word in each line of the file.\n",
    "        target_words: A list of the second word in each line of the file.\n",
    "    \"\"\"\n",
    "    lines = read_lines(filename)\n",
    "    source_words, target_words = [], []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            source, target = line.split()\n",
    "            source_words.append(source)\n",
    "            target_words.append(target)\n",
    "    return source_words, target_words\n",
    "\n",
    "\n",
    "def all_alpha_or_dash(s):\n",
    "    \"\"\"Helper function to check whether a string is alphabetic, allowing dashes '-'.\n",
    "    \"\"\"\n",
    "    return all(c.isalpha() or c == '-' for c in s)\n",
    "\n",
    "\n",
    "def filter_lines(lines):\n",
    "    \"\"\"Filters lines to consist of only alphabetic characters or dashes \"-\".\n",
    "    \"\"\"\n",
    "    return [line for line in lines if all_alpha_or_dash(line)]\n",
    "\n",
    "\n",
    "def load_data(file_name):\n",
    "    \"\"\"Loads (English, Pig-Latin) word pairs, and creates mappings from characters to indexes.\n",
    "    \"\"\"\n",
    "    path = \"./data/{}.txt\".format(file_name)\n",
    "    source_lines, target_lines = read_pairs(path)\n",
    "\n",
    "    # Filter lines\n",
    "    source_lines = filter_lines(source_lines)\n",
    "    target_lines = filter_lines(target_lines)\n",
    "\n",
    "    all_characters = set(''.join(source_lines)) | set(''.join(target_lines))\n",
    "\n",
    "    # Create a dictionary mapping each character to a unique index\n",
    "    char_to_index = { char: index for (index, char) in enumerate(sorted(list(all_characters))) }\n",
    "\n",
    "    # Add start and end tokens to the dictionary\n",
    "    start_token = len(char_to_index)\n",
    "    end_token = len(char_to_index) + 1\n",
    "    char_to_index['SOS'] = start_token\n",
    "    char_to_index['EOS'] = end_token\n",
    "\n",
    "    # Create the inverse mapping, from indexes to characters (used to decode the model's predictions)\n",
    "    index_to_char = { index: char for (char, index) in char_to_index.items() }\n",
    "\n",
    "    # Store the final size of the vocabulary\n",
    "    vocab_size = len(char_to_index)\n",
    "\n",
    "    line_pairs = list(set(zip(source_lines, target_lines)))  # Python 3\n",
    "\n",
    "    idx_dict = { 'char_to_index': char_to_index,\n",
    "                 'index_to_char': index_to_char,\n",
    "                 'start_token': start_token,\n",
    "                 'end_token': end_token }\n",
    "\n",
    "    return line_pairs, vocab_size, idx_dict\n",
    "\n",
    "\n",
    "def create_dict(pairs):\n",
    "    \"\"\"Creates a mapping { (source_length, target_length): [list of (source, target) pairs]\n",
    "    This is used to make batches: each batch consists of two parallel tensors, one containing\n",
    "    all source indexes and the other containing all corresponding target indexes.\n",
    "    Within a batch, all the source words are the same length, and all the target words are\n",
    "    the same length.\n",
    "    \"\"\"\n",
    "    unique_pairs = list(set(pairs))  # Find all unique (source, target) pairs\n",
    "\n",
    "    d = defaultdict(list)\n",
    "    for (s,t) in unique_pairs:\n",
    "        d[(len(s), len(t))].append((s,t))\n",
    "\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRWfRdmVVjUl"
   },
   "source": [
    "## Training and evaluation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wa5-onJhoSeM"
   },
   "outputs": [],
   "source": [
    "def string_to_index_list(s, char_to_index, end_token):\n",
    "    \"\"\"Converts a sentence into a list of indexes (for each character).\n",
    "    \"\"\"\n",
    "    return [char_to_index[char] for char in s] + [end_token]  # Adds the end token to each index list\n",
    "\n",
    "\n",
    "def translate_sentence(sentence, encoder, decoder, idx_dict, opts):\n",
    "    \"\"\"Translates a sentence from English to Pig-Latin, by splitting the sentence into\n",
    "    words (whitespace-separated), running the encoder-decoder model to translate each\n",
    "    word independently, and then stitching the words back together with spaces between them.\n",
    "    \"\"\"\n",
    "    if idx_dict is None:\n",
    "      line_pairs, vocab_size, idx_dict = load_data(opts['data_file_name'])\n",
    "    return ' '.join([translate(word, encoder, decoder, idx_dict, opts) for word in sentence.split()])\n",
    "\n",
    "\n",
    "def translate(input_string, encoder, decoder, idx_dict, opts):\n",
    "    \"\"\"Translates a given string from English to Pig-Latin.\n",
    "    \"\"\"\n",
    "\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "    index_to_char = idx_dict['index_to_char']\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "\n",
    "    max_generated_chars = 20\n",
    "    gen_string = ''\n",
    "\n",
    "    indexes = string_to_index_list(input_string, char_to_index, end_token)\n",
    "    indexes = to_var(torch.LongTensor(indexes).unsqueeze(0), opts.cuda)  # Unsqueeze to make it like BS = 1\n",
    "\n",
    "    encoder_annotations, encoder_last_hidden, encoder_last_cell = encoder(indexes)\n",
    "\n",
    "    decoder_hidden = encoder_last_hidden\n",
    "    decoder_cell = encoder_last_cell\n",
    "    decoder_input = to_var(torch.LongTensor([[start_token]]), opts.cuda)  # For BS = 1\n",
    "    decoder_inputs = decoder_input\n",
    "\n",
    "    for i in range(max_generated_chars):\n",
    "        ## slow decoding, recompute everything at each time\n",
    "        decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, decoder_hidden, decoder_cell)\n",
    "\n",
    "        generated_words = F.softmax(decoder_outputs, dim=2).max(2)[1]\n",
    "        ni = generated_words.cpu().numpy().reshape(-1)  # LongTensor of size 1\n",
    "        ni = ni[-1] #latest output token\n",
    "\n",
    "        decoder_inputs = torch.cat([decoder_input, generated_words], dim=1)\n",
    "\n",
    "        if ni == end_token:\n",
    "            break\n",
    "        else:\n",
    "            gen_string = \"\".join(\n",
    "                [index_to_char[int(item)] \n",
    "                for item in generated_words.cpu().numpy().reshape(-1)])\n",
    "\n",
    "    return gen_string\n",
    "\n",
    "\n",
    "def visualize_attention(input_string, encoder, decoder, idx_dict, opts):\n",
    "    \"\"\"Generates a heatmap to show where attention is focused in each decoder step.\n",
    "    \"\"\"\n",
    "    if idx_dict is None:\n",
    "      line_pairs, vocab_size, idx_dict = load_data(opts['data_file_name'])\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "    index_to_char = idx_dict['index_to_char']\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "\n",
    "    max_generated_chars = 20\n",
    "    gen_string = ''\n",
    "\n",
    "    indexes = string_to_index_list(input_string, char_to_index, end_token)\n",
    "    indexes = to_var(torch.LongTensor(indexes).unsqueeze(0), opts.cuda)  # Unsqueeze to make it like BS = 1\n",
    "\n",
    "    encoder_annotations, encoder_hidden, encoder_cell = encoder(indexes)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_cell = encoder_cell\n",
    "    decoder_input = to_var(torch.LongTensor([[start_token]]), opts.cuda)  # For BS = 1\n",
    "    decoder_inputs = decoder_input\n",
    "\n",
    "    produced_end_token = False\n",
    "\n",
    "    for i in range(max_generated_chars):\n",
    "        ## slow decoding, recompute everything at each time\n",
    "        decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, decoder_hidden, decoder_cell)\n",
    "        generated_words = F.softmax(decoder_outputs, dim=2).max(2)[1]\n",
    "        ni = generated_words.cpu().numpy().reshape(-1)  # LongTensor of size 1\n",
    "        ni = ni[-1] #latest output token\n",
    "\n",
    "        decoder_inputs = torch.cat([decoder_input, generated_words], dim=1)\n",
    "\n",
    "        if ni == end_token:\n",
    "            break\n",
    "        else:\n",
    "            gen_string = \"\".join(\n",
    "                [index_to_char[int(item)] \n",
    "                for item in generated_words.cpu().numpy().reshape(-1)])\n",
    "    \n",
    "    if isinstance(attention_weights, tuple):\n",
    "      ## transformer's attention mweights\n",
    "      attention_weights, self_attention_weights = attention_weights\n",
    "    \n",
    "    all_attention_weights = attention_weights.data.cpu().numpy()\n",
    "    \n",
    "    for i in range(len(all_attention_weights)):\n",
    "        attention_weights_matrix = all_attention_weights[i].squeeze()\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        cax = ax.matshow(attention_weights_matrix, cmap='bone')\n",
    "        fig.colorbar(cax)\n",
    "\n",
    "        # Set up axes\n",
    "        ax.set_yticklabels([''] + list(input_string) + ['EOS'], rotation=90)\n",
    "        ax.set_xticklabels([''] + list(gen_string) + (['EOS'] if produced_end_token else []))\n",
    "\n",
    "        # Show label at every tick\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        # Add title\n",
    "        plt.xlabel('Attention weights to the source sentence in layer {}'.format(i+1))\n",
    "        plt.tight_layout()\n",
    "        plt.grid('off')\n",
    "        plt.show()\n",
    "\n",
    "    return gen_string\n",
    "\n",
    "\n",
    "def compute_loss(data_dict, encoder, decoder, idx_dict, criterion, optimizer, opts):\n",
    "    \"\"\"Train/Evaluate the model on a dataset.\n",
    "\n",
    "    Arguments:\n",
    "        data_dict: The validation/test word pairs, organized by source and target lengths.\n",
    "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
    "        decoder: A decoder model (with or without attention) to generate output tokens.\n",
    "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
    "        criterion: Used to compute the CrossEntropyLoss for each decoder output.\n",
    "        optimizer: Train the weights if an optimizer is given. None if only evaluate the model. \n",
    "        opts: The command-line arguments.\n",
    "\n",
    "    Returns:\n",
    "        mean_loss: The average loss over all batches from data_dict.\n",
    "    \"\"\"\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "\n",
    "    losses = []\n",
    "    for key in data_dict:\n",
    "        input_strings, target_strings = zip(*data_dict[key])\n",
    "        input_tensors = [torch.LongTensor(string_to_index_list(s, char_to_index, end_token)) for s in input_strings]\n",
    "        target_tensors = [torch.LongTensor(string_to_index_list(s, char_to_index, end_token)) for s in target_strings]\n",
    "\n",
    "        num_tensors = len(input_tensors)\n",
    "        num_batches = int(np.ceil(num_tensors / float(opts.batch_size)))\n",
    "\n",
    "        for i in range(num_batches):\n",
    "\n",
    "            start = i * opts.batch_size\n",
    "            end = start + opts.batch_size\n",
    "\n",
    "            inputs = to_var(torch.stack(input_tensors[start:end]), opts.cuda)\n",
    "            targets = to_var(torch.stack(target_tensors[start:end]), opts.cuda)\n",
    "\n",
    "            # The batch size may be different in each epoch\n",
    "            BS = inputs.size(0)\n",
    "\n",
    "            encoder_annotations, encoder_hidden, encoder_cell = encoder(inputs)\n",
    "\n",
    "            # The last hidden state of the encoder becomes the first hidden state of the decoder\n",
    "            decoder_hidden = encoder_hidden\n",
    "            decoder_cell = encoder_cell\n",
    "\n",
    "            start_vector = torch.ones(BS).long().unsqueeze(1) * start_token  # BS x 1 --> 16x1  CHECKED\n",
    "            decoder_input = to_var(start_vector, opts.cuda)  # BS x 1 --> 16x1  CHECKED\n",
    "\n",
    "            loss = 0.0\n",
    "\n",
    "            seq_len = targets.size(1)  # Gets seq_len from BS x seq_len\n",
    "\n",
    "            decoder_inputs = torch.cat([decoder_input, targets[:, 0:-1]], dim=1)  # Gets decoder inputs by shifting the targets to the right \n",
    "\n",
    "            decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, decoder_hidden, decoder_cell)\n",
    "            decoder_outputs_flatten = decoder_outputs.view(-1, decoder_outputs.size(2))\n",
    "            targets_flatten = targets.view(-1)\n",
    "            \n",
    "            loss = criterion(decoder_outputs_flatten, targets_flatten)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            ## training if an optimizer is provided\n",
    "            if optimizer:\n",
    "              # Zero gradients\n",
    "              optimizer.zero_grad()\n",
    "              # Compute gradients\n",
    "              loss.backward()\n",
    "              # Update the parameters of the encoder and decoder\n",
    "              optimizer.step()\n",
    "\n",
    "    return losses\n",
    "\n",
    "  \n",
    "\n",
    "def training_loop(train_dict, val_dict, idx_dict, encoder, decoder, criterion, optimizer, opts):\n",
    "    \"\"\"Runs the main training loop; evaluates the model on the val set every epoch.\n",
    "        * Prints training and val loss each epoch.\n",
    "        * Prints qualitative translation results each epoch using TEST_SENTENCE\n",
    "        * Saves an attention map for TEST_WORD_ATTN each epoch\n",
    "        * Returns loss curves for comparison\n",
    "\n",
    "    Arguments:\n",
    "        train_dict: The training word pairs, organized by source and target lengths.\n",
    "        val_dict: The validation word pairs, organized by source and target lengths.\n",
    "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
    "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
    "        decoder: A decoder model (with or without attention) to generate output tokens.\n",
    "        criterion: Used to compute the CrossEntropyLoss for each decoder output.\n",
    "        optimizer: Implements a step rule to update the parameters of the encoder and decoder.\n",
    "        opts: The command-line arguments.\n",
    "    \n",
    "    Returns:\n",
    "        losses: Lists containing training and validation loss curves.\n",
    "    \"\"\"\n",
    "\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "\n",
    "    loss_log = open(os.path.join(opts.checkpoint_path, 'loss_log.txt'), 'w')\n",
    "\n",
    "    best_val_loss = 1e6\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    mean_train_losses = []\n",
    "    mean_val_losses = []\n",
    "\n",
    "    early_stopping_counter = 0\n",
    "    \n",
    "    for epoch in range(opts.nepochs):\n",
    "\n",
    "        optimizer.param_groups[0]['lr'] *= opts.lr_decay\n",
    "        \n",
    "        train_loss = compute_loss(train_dict, encoder, decoder, idx_dict, criterion, optimizer, opts)\n",
    "        val_loss = compute_loss(val_dict, encoder, decoder, idx_dict, criterion, None, opts)\n",
    "\n",
    "        mean_train_loss = np.mean(train_loss)\n",
    "        mean_val_loss = np.mean(val_loss)\n",
    "\n",
    "        if mean_val_loss < best_val_loss:\n",
    "            checkpoint(encoder, decoder, idx_dict, opts)\n",
    "            best_val_loss = mean_val_loss\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "        \n",
    "        if early_stopping_counter > opts.early_stopping_patience:\n",
    "            print(\"Validation loss has not improved in {} epochs, stopping early\".format(opts.early_stopping_patience))\n",
    "            print(\"Obtained lowest validation loss of: {}\".format(best_val_loss))\n",
    "            return (train_losses, mean_val_losses)\n",
    "\n",
    "        gen_string = translate_sentence(TEST_SENTENCE, encoder, decoder, idx_dict, opts)\n",
    "        print(\"Epoch: {:3d} | Train loss: {:.3f} | Val loss: {:.3f} | Gen: {:20s}\".format(epoch, mean_train_loss, mean_val_loss, gen_string))\n",
    "\n",
    "        loss_log.write('{} {} {}\\n'.format(epoch, train_loss, val_loss))\n",
    "        loss_log.flush()\n",
    "\n",
    "        train_losses += train_loss\n",
    "        val_losses += val_loss\n",
    "\n",
    "        mean_train_losses.append(mean_train_loss)\n",
    "        mean_val_losses.append(mean_val_loss)\n",
    "\n",
    "        save_loss_plot(mean_train_losses, mean_val_losses, opts)\n",
    "\n",
    "    print(\"Obtained lowest validation loss of: {}\".format(best_val_loss))\n",
    "    return (train_losses, mean_val_losses)\n",
    "\n",
    "\n",
    "def print_data_stats(line_pairs, vocab_size, idx_dict):\n",
    "    \"\"\"Prints example word pairs, the number of data points, and the vocabulary.\n",
    "    \"\"\"\n",
    "    print('=' * 80)\n",
    "    print('Data Stats'.center(80))\n",
    "    print('-' * 80)\n",
    "    for pair in line_pairs[:5]:\n",
    "        print(pair)\n",
    "    print('Num unique word pairs: {}'.format(len(line_pairs)))\n",
    "    print('Vocabulary: {}'.format(idx_dict['char_to_index'].keys()))\n",
    "    print('Vocab size: {}'.format(vocab_size))\n",
    "    print('=' * 80)\n",
    "\n",
    "\n",
    "def train(opts):\n",
    "    line_pairs, vocab_size, idx_dict = load_data(opts['data_file_name'])\n",
    "    print_data_stats(line_pairs, vocab_size, idx_dict)\n",
    "\n",
    "    # Split the line pairs into an 80% train and 20% val split\n",
    "    num_lines = len(line_pairs)\n",
    "    num_train = int(0.8 * num_lines)\n",
    "    train_pairs, val_pairs = line_pairs[:num_train], line_pairs[num_train:]\n",
    "\n",
    "    # Group the data by the lengths of the source and target words, to form batches\n",
    "    train_dict = create_dict(train_pairs)\n",
    "    val_dict = create_dict(val_pairs)\n",
    "\n",
    "    ##########################################################################\n",
    "    ### Setup: Create Encoder, Decoder, Learning Criterion, and Optimizers ###\n",
    "    ##########################################################################\n",
    "    if opts.encoder_type == \"rnn\":\n",
    "        encoder = LSTMEncoder(vocab_size=vocab_size, \n",
    "                              hidden_size=opts.hidden_size, \n",
    "                              opts=opts)\n",
    "    elif opts.encoder_type == \"transformer\":\n",
    "        encoder = TransformerEncoder(vocab_size=vocab_size, \n",
    "                                     hidden_size=opts.hidden_size, \n",
    "                                     num_layers=opts.num_transformer_layers,\n",
    "                                     opts=opts)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if opts.decoder_type == 'rnn':\n",
    "        decoder = RNNDecoder(vocab_size=vocab_size, \n",
    "                             hidden_size=opts.hidden_size)\n",
    "    elif opts.decoder_type == 'rnn_attention':\n",
    "        decoder = RNNAttentionDecoder(vocab_size=vocab_size, \n",
    "                                      hidden_size=opts.hidden_size, \n",
    "                                      attention_type=opts.attention_type)\n",
    "    elif opts.decoder_type == 'transformer':\n",
    "        decoder = TransformerDecoder(vocab_size=vocab_size, \n",
    "                                     hidden_size=opts.hidden_size, \n",
    "                                     num_layers=opts.num_transformer_layers)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    #### setup checkpoint path\n",
    "    model_name = 'h{}-bs{}-{}-{}'.format(opts.hidden_size, \n",
    "                                      opts.batch_size, \n",
    "                                      opts.decoder_type,\n",
    "                                      opts.data_file_name)\n",
    "    opts.checkpoint_path = model_name\n",
    "    create_dir_if_not_exists(opts.checkpoint_path)\n",
    "    ####\n",
    "\n",
    "    if opts.cuda:\n",
    "        encoder.cuda()\n",
    "        decoder.cuda()\n",
    "        print(\"Moved models to GPU!\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=opts.learning_rate)\n",
    "\n",
    "    try:\n",
    "        losses = training_loop(train_dict, val_dict, idx_dict, encoder, \n",
    "                               decoder, criterion, optimizer, opts)\n",
    "    except KeyboardInterrupt:\n",
    "        print('Exiting early from training.')\n",
    "        return encoder, decoder, losses\n",
    "      \n",
    "    return encoder, decoder, losses\n",
    "\n",
    "\n",
    "def print_opts(opts):\n",
    "    \"\"\"Prints the values of all command-line arguments.\n",
    "    \"\"\"\n",
    "    print('=' * 80)\n",
    "    print('Opts'.center(80))\n",
    "    print('-' * 80)\n",
    "    for key in opts.__dict__:\n",
    "        print('{:>30}: {:<30}'.format(key, opts.__dict__[key]).center(80))\n",
    "    print('=' * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yh08KhgnA30"
   },
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aROU2xZanDKq",
    "outputId": "363c6425-bf23-41c8-e81d-6d1204581332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/pig_latin_small.txt\n",
      "Downloading data from http://www.cs.toronto.edu/~jba/pig_latin_small.txt\n",
      "data/pig_latin_large.txt\n",
      "Downloading data from http://www.cs.toronto.edu/~jba/pig_latin_large.txt\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# Download Translation datasets\n",
    "######################################################################\n",
    "data_fpath = get_file(fname='pig_latin_small.txt', \n",
    "                         origin='http://www.cs.toronto.edu/~jba/pig_latin_small.txt', \n",
    "                         untar=False)\n",
    "\n",
    "data_fpath = get_file(fname='pig_latin_large.txt', \n",
    "                         origin='http://www.cs.toronto.edu/~jba/pig_latin_large.txt', \n",
    "                         untar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDYMr7NclZdw"
   },
   "source": [
    "# Part 1: Long Short-Term Memory Unit (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCae1mOUlZrC"
   },
   "source": [
    "## Step 1: LSTM Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOnALRQkkjDO"
   },
   "outputs": [],
   "source": [
    "class MyLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MyLSTMCell, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.Wii = nn.Linear(input_size, hidden_size)\n",
    "        self.Whi = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        self.Wif = nn.Linear(input_size, hidden_size)\n",
    "        self.Whf = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        self.Wig = nn.Linear(input_size, hidden_size)\n",
    "        self.Whg = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        self.Wio = nn.Linear(input_size, hidden_size)\n",
    "        self.Who = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        \"\"\"Forward pass of the LSTM computation for one time step.\n",
    "\n",
    "        Arguments\n",
    "            x: batch_size x input_size\n",
    "            h_prev: batch_size x hidden_size\n",
    "            c_prev: batch_size x hidden_size\n",
    "\n",
    "        Returns:\n",
    "            h_new: batch_size x hidden_size\n",
    "            c_new: batch_size x hidden_size\n",
    "        \"\"\"\n",
    "\n",
    "        i = self.sigmoid(self.Wii(x) + self.Whi(h_prev))\n",
    "        f = self.sigmoid(self.Wif(x) + self.Whf(h_prev))\n",
    "        g = self.tanh(self.Wig(x) + self.Whg(h_prev))\n",
    "        o = self.sigmoid(self.Wio(x) + self.Who(h_prev))\n",
    "        c_new = torch.mul(f, c_prev) + torch.mul(i, g)\n",
    "        h_new = torch.mul(o, self.tanh(c_new))\n",
    "        return h_new, c_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecEq4TP2lZ4Z"
   },
   "source": [
    "## Step 2: LSTM Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8jDNim2fmVJV"
   },
   "outputs": [],
   "source": [
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, opts):\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.opts = opts\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.lstm = MyLSTMCell(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass of the encoder RNN.\n",
    "\n",
    "        Arguments:\n",
    "            inputs: Input token indexes across a batch for all time steps in the sequence. (batch_size x seq_len)\n",
    "\n",
    "        Returns:\n",
    "            annotations: The hidden states computed at each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "            hidden: The final hidden state of the encoder, for each sequence in a batch. (batch_size x hidden_size)\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size, seq_len = inputs.size()\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        cell = self.init_hidden(batch_size)\n",
    "\n",
    "        encoded = self.embedding(inputs)  # batch_size x seq_len x hidden_size\n",
    "        annotations = []\n",
    "\n",
    "        for i in range(seq_len):\n",
    "            x = encoded[:,i,:]  # Get the current time step, across the whole batch\n",
    "            hidden, cell = self.lstm(x, hidden, cell)\n",
    "            annotations.append(hidden)\n",
    "\n",
    "        annotations = torch.stack(annotations, dim=1)\n",
    "        return annotations, hidden, cell\n",
    "\n",
    "    def init_hidden(self, bs):\n",
    "        \"\"\"Creates a tensor of zeros to represent the initial hidden states\n",
    "        of a batch of sequences.\n",
    "\n",
    "        Arguments:\n",
    "            bs: The batch size for the initial hidden state.\n",
    "\n",
    "        Returns:\n",
    "            hidden: An initial hidden state of all zeros. (batch_size x hidden_size)\n",
    "        \"\"\"\n",
    "        return to_var(torch.zeros(bs, self.hidden_size), self.opts.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HvwizYM9ma4p"
   },
   "outputs": [],
   "source": [
    "class RNNDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(RNNDecoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.rnn = MyLSTMCell(input_size=hidden_size, hidden_size=hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, annotations, hidden_init, cell_init):\n",
    "        \"\"\"Forward pass of the non-attentional decoder RNN.\n",
    "\n",
    "        Arguments:\n",
    "            inputs: Input token indexes across a batch. (batch_size x seq_len)\n",
    "            annotations: This is not used here. It just maintains consistency with the\n",
    "                    interface used by the AttentionDecoder class.\n",
    "            hidden_init: The hidden states from the last step of encoder, across a batch. (batch_size x hidden_size)\n",
    "            cell_init: The cell states from the last step of encoder, across a batch. (batch_size x hidden_size)\n",
    "\n",
    "        Returns:\n",
    "            output: Un-normalized scores for each token in the vocabulary, across a batch for all the decoding time steps. (batch_size x decoder_seq_len x vocab_size)\n",
    "            None\n",
    "        \"\"\"        \n",
    "        batch_size, seq_len = inputs.size()\n",
    "        embed = self.embedding(inputs)  # batch_size x seq_len x hidden_size        \n",
    "\n",
    "        hiddens = []\n",
    "        h_prev = hidden_init\n",
    "        c_prev = cell_init\n",
    "\n",
    "        for i in range(seq_len):\n",
    "            x = embed[:,i,:]  # Get the current time step input tokens, across the whole batch\n",
    "            h_prev, c_prev = self.rnn(x, h_prev, c_prev)  # batch_size x hidden_size\n",
    "            hiddens.append(h_prev)\n",
    "\n",
    "        hiddens = torch.stack(hiddens, dim=1) # batch_size x seq_len x hidden_size\n",
    "        \n",
    "        output = self.out(hiddens)  # batch_size x seq_len x vocab_size\n",
    "        return output, None  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSDTbsydlaGI"
   },
   "source": [
    "## Step 3: Training and Analysis\n",
    "Train the following language model comprised of recurrent encoder and decoders. \n",
    "\n",
    "First, we train on the smaller dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XmVuXTozTPF7",
    "outputId": "09f70bf7-4719-4e31-8004-e3987414f7c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                                      Opts                                      \n",
      "--------------------------------------------------------------------------------\n",
      "                         data_file_name: pig_latin_small                        \n",
      "                                   cuda: 1                                      \n",
      "                                nepochs: 50                                     \n",
      "                         checkpoint_dir: checkpoints                            \n",
      "                          learning_rate: 0.005                                  \n",
      "                               lr_decay: 0.99                                   \n",
      "                early_stopping_patience: 20                                     \n",
      "                             batch_size: 64                                     \n",
      "                            hidden_size: 32                                     \n",
      "                           encoder_type: rnn                                    \n",
      "                           decoder_type: rnn                                    \n",
      "                         attention_type:                                        \n",
      "================================================================================\n",
      "================================================================================\n",
      "                                   Data Stats                                   \n",
      "--------------------------------------------------------------------------------\n",
      "('leisurely', 'eisurelylay')\n",
      "('subsist', 'ubsistsay')\n",
      "('truth', 'uthtray')\n",
      "('supposition', 'uppositionsay')\n",
      "('discovering', 'iscoveringday')\n",
      "Num unique word pairs: 3198\n",
      "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
      "Vocab size: 29\n",
      "================================================================================\n",
      "Moved models to GPU!\n",
      "Epoch:   0 | Train loss: 2.328 | Val loss: 2.066 | Gen: ingay insay insay-onsay-onay insay insay-onsay\n",
      "Epoch:   1 | Train loss: 1.875 | Val loss: 1.894 | Gen: ingay ay-ay indeday-ongay ingway ongway-ongay\n",
      "Epoch:   2 | Train loss: 1.699 | Val loss: 1.778 | Gen: iway ansay ingssenssay-oncay ingway onday-onway\n",
      "Epoch:   3 | Train loss: 1.558 | Val loss: 1.663 | Gen: eway antay ondingway-onday isway ontay-onway\n",
      "Epoch:   4 | Train loss: 1.450 | Val loss: 1.600 | Gen: eway ansay ondingsay-onday-oay isway ondeway\n",
      "Epoch:   5 | Train loss: 1.358 | Val loss: 1.539 | Gen: eway ansay ondingway-oday-oacay isway ondeway\n",
      "Epoch:   6 | Train loss: 1.264 | Val loss: 1.460 | Gen: etay aray onconsingway isway oncorway\n",
      "Epoch:   7 | Train loss: 1.179 | Val loss: 1.407 | Gen: eway arsay onconconay-ouday isway ondgay-ousay\n",
      "Epoch:   8 | Train loss: 1.105 | Val loss: 1.354 | Gen: etay arsay onconsingsay isway oringsway\n",
      "Epoch:   9 | Train loss: 1.044 | Val loss: 1.310 | Gen: etay ay-arcay onconcencay-oacay isway oursedway\n",
      "Epoch:  10 | Train loss: 0.989 | Val loss: 1.266 | Gen: etay arsay onconcingnay isway orfingway\n",
      "Epoch:  11 | Train loss: 0.924 | Val loss: 1.235 | Gen: ethay arsway oncindensiblay isway orfingway\n",
      "Epoch:  12 | Train loss: 0.880 | Val loss: 1.206 | Gen: etay arsway oncontingshay isway orfay-ingway\n",
      "Epoch:  13 | Train loss: 0.827 | Val loss: 1.171 | Gen: etay arsway oncintedsay-oacay isway orfay-ighay\n",
      "Epoch:  14 | Train loss: 0.775 | Val loss: 1.150 | Gen: ethay arway onconsingsay isway orfay-ingway\n",
      "Epoch:  15 | Train loss: 0.729 | Val loss: 1.109 | Gen: ethay ariway oncindingsay isway orfingway\n",
      "Epoch:  16 | Train loss: 0.698 | Val loss: 1.124 | Gen: ethay ariway oncindingbay isway orfingway\n",
      "Epoch:  17 | Train loss: 0.678 | Val loss: 1.076 | Gen: ethay ariway oncintedshay isway orfay-ingway\n",
      "Epoch:  18 | Train loss: 0.637 | Val loss: 1.101 | Gen: ethay ariway oncintiondway isway orfsay\n",
      "Epoch:  19 | Train loss: 0.609 | Val loss: 1.037 | Gen: ethay ariway oncitingdonay isway orfingway\n",
      "Epoch:  20 | Train loss: 0.586 | Val loss: 1.038 | Gen: ethay ariway oncintiongay isway orfingway\n",
      "Epoch:  21 | Train loss: 0.572 | Val loss: 1.015 | Gen: ethay aisway oncintedchay isway orfshay\n",
      "Epoch:  22 | Train loss: 0.547 | Val loss: 1.060 | Gen: ehay ariway oncinditionway isway orfingway\n",
      "Epoch:  23 | Train loss: 0.529 | Val loss: 1.014 | Gen: ethay airway oncitiondenway isway ogfingsay\n",
      "Epoch:  24 | Train loss: 0.500 | Val loss: 1.026 | Gen: ethay airway oncitingdonay isway orfingway\n",
      "Epoch:  25 | Train loss: 0.493 | Val loss: 0.994 | Gen: ethay airway ondisiontencay isway orfingway\n",
      "Epoch:  26 | Train loss: 0.489 | Val loss: 0.988 | Gen: ethay airway oncitiondenway isway orfingway\n",
      "Epoch:  27 | Train loss: 0.473 | Val loss: 0.972 | Gen: ethay ariway ondisinestay isway orfingway\n",
      "Epoch:  28 | Train loss: 0.450 | Val loss: 0.975 | Gen: ethay airway oncitingdonay isway orfingway\n",
      "Epoch:  29 | Train loss: 0.426 | Val loss: 0.967 | Gen: ethay airway ondisinedlay isway orfingway\n",
      "Epoch:  30 | Train loss: 0.414 | Val loss: 0.989 | Gen: ethay airway ondisinedhay isway okfirray\n",
      "Epoch:  31 | Train loss: 0.405 | Val loss: 0.949 | Gen: ethay airway oncicationdway isway orfingway\n",
      "Epoch:  32 | Train loss: 0.393 | Val loss: 0.976 | Gen: ethay ariway ondisinedchay isway orfingway\n",
      "Epoch:  33 | Train loss: 0.386 | Val loss: 0.979 | Gen: ethay ariway ondisinedchay isway okfirway\n",
      "Epoch:  34 | Train loss: 0.385 | Val loss: 0.936 | Gen: ethay airway ondisinestay isway orfingway\n",
      "Epoch:  35 | Train loss: 0.365 | Val loss: 0.958 | Gen: ethay airway ondisinedchay isway orfingway\n",
      "Epoch:  36 | Train loss: 0.346 | Val loss: 0.953 | Gen: ethay airway ondisinedchay isway orfingway\n",
      "Epoch:  37 | Train loss: 0.333 | Val loss: 0.957 | Gen: ethay airway ondisinedchay isway orfingway\n",
      "Epoch:  38 | Train loss: 0.327 | Val loss: 0.998 | Gen: ethay airway ondisionenday isway orfingway\n",
      "Epoch:  39 | Train loss: 0.326 | Val loss: 0.982 | Gen: etay airway ondisinedchay isway orkwingway\n",
      "Epoch:  40 | Train loss: 0.318 | Val loss: 0.995 | Gen: ethay airway ondisinedhay isway orkingway\n",
      "Epoch:  41 | Train loss: 0.312 | Val loss: 0.986 | Gen: etay airway ondisinedonay isway orfingway\n",
      "Epoch:  42 | Train loss: 0.302 | Val loss: 1.027 | Gen: ethay airway ondisinoneday isway orfingway\n",
      "Epoch:  43 | Train loss: 0.297 | Val loss: 0.997 | Gen: etay airway ondisinedchay isway orkingway\n",
      "Epoch:  44 | Train loss: 0.310 | Val loss: 1.081 | Gen: ethay ariway ondistionceday isway orkingrway\n",
      "Epoch:  45 | Train loss: 0.346 | Val loss: 1.032 | Gen: ethay airway ondistionneway isway orfingway\n",
      "Epoch:  46 | Train loss: 0.322 | Val loss: 0.975 | Gen: ethay airway ondisinedhay isway ourfhay\n",
      "Epoch:  47 | Train loss: 0.300 | Val loss: 1.007 | Gen: ethay airway ondistionnecay isway orkwingway\n",
      "Epoch:  48 | Train loss: 0.275 | Val loss: 0.957 | Gen: ethay airway ondisinedhay isway orkingway\n",
      "Epoch:  49 | Train loss: 0.258 | Val loss: 0.977 | Gen: ethay airway ondistionnecay isway orkwingway\n",
      "Obtained lowest validation loss of: 0.9358342129450578\n",
      "source:\t\tthe air conditioning is working \n",
      "translated:\tethay airway ondistionnecay isway orkwingway\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = 'the air conditioning is working'\n",
    "\n",
    "rnn_args_s = AttrDict()\n",
    "args_dict = {\n",
    "              'data_file_name': 'pig_latin_small',\n",
    "              'cuda':True,\n",
    "              'nepochs':50,\n",
    "              'checkpoint_dir':\"checkpoints\",\n",
    "              'learning_rate':0.005,\n",
    "              'lr_decay':0.99,\n",
    "              'early_stopping_patience':20,\n",
    "              'batch_size':64,\n",
    "              'hidden_size':32,\n",
    "              'encoder_type': 'rnn', # options: rnn / transformer\n",
    "              'decoder_type': 'rnn', # options: rnn / rnn_attention / transformer\n",
    "              'attention_type': '',  # options: additive / scaled_dot\n",
    "}\n",
    "rnn_args_s.update(args_dict)\n",
    "\n",
    "print_opts(rnn_args_s)\n",
    "rnn_encode_s, rnn_decoder_s, rnn_losses_s = train(rnn_args_s)\n",
    "\n",
    "translated = translate_sentence(TEST_SENTENCE, rnn_encode_s, rnn_decoder_s, None, rnn_args_s)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mR97V_NtER6"
   },
   "source": [
    "Next, we train on the larger dataset. This experiment investigates if increasing dataset size improves model generalization on the validation set. \n",
    "\n",
    "For a fair comparison, the number of iterations (not number of epochs) for each run should be similar. This is done in a rough and dirty way by adjusting the batch size so approximately the same number of batches is processed per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H3YLrAjsmx_W",
    "outputId": "5675e7f4-e093-46f3-ca95-5f9151fd9275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                                      Opts                                      \n",
      "--------------------------------------------------------------------------------\n",
      "                         data_file_name: pig_latin_large                        \n",
      "                                   cuda: 1                                      \n",
      "                                nepochs: 50                                     \n",
      "                         checkpoint_dir: checkpoints                            \n",
      "                          learning_rate: 0.005                                  \n",
      "                               lr_decay: 0.99                                   \n",
      "                early_stopping_patience: 10                                     \n",
      "                             batch_size: 512                                    \n",
      "                            hidden_size: 32                                     \n",
      "                           encoder_type: rnn                                    \n",
      "                           decoder_type: rnn                                    \n",
      "                         attention_type:                                        \n",
      "================================================================================\n",
      "================================================================================\n",
      "                                   Data Stats                                   \n",
      "--------------------------------------------------------------------------------\n",
      "('albuquerque', 'albuquerqueway')\n",
      "('ejaculation', 'ejaculationway')\n",
      "('kenwood', 'enwoodkay')\n",
      "('satire', 'atiresay')\n",
      "('rite', 'iteray')\n",
      "Num unique word pairs: 22402\n",
      "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
      "Vocab size: 29\n",
      "================================================================================\n",
      "Moved models to GPU!\n",
      "Epoch:   0 | Train loss: 2.376 | Val loss: 2.019 | Gen: esay-ay ay-ay-ay ontay-ay-ay intay ontay-ay\n",
      "Epoch:   1 | Train loss: 1.908 | Val loss: 1.844 | Gen: eray-ay ay-ay-ay onteray-ay-ay-ay intay onteray-ay\n",
      "Epoch:   2 | Train loss: 1.719 | Val loss: 1.737 | Gen: eray ay-ay elfay-interay-ay inway ontay-ay-ay\n",
      "Epoch:   3 | Train loss: 1.581 | Val loss: 1.622 | Gen: edway away onterinteray-ay inway odway-ay-ay\n",
      "Epoch:   4 | Train loss: 1.460 | Val loss: 1.521 | Gen: enway away intingertionway isway odway-ayday\n",
      "Epoch:   5 | Train loss: 1.335 | Val loss: 1.428 | Gen: etay away ontentinedway isway odway-oday\n",
      "Epoch:   6 | Train loss: 1.230 | Val loss: 1.412 | Gen: etay away oncintergay-ayway isway odway-orday\n",
      "Epoch:   7 | Train loss: 1.158 | Val loss: 1.350 | Gen: etay away oncintergray isway odirgray\n",
      "Epoch:   8 | Train loss: 1.086 | Val loss: 1.302 | Gen: etay airway ngay-ingay-inway isway ororysay\n",
      "Epoch:   9 | Train loss: 1.036 | Val loss: 1.274 | Gen: etay airway oncingray-inway isway ororinay\n",
      "Epoch:  10 | Train loss: 0.983 | Val loss: 1.259 | Gen: etay airway oncinghay-inway isway odingray\n",
      "Epoch:  11 | Train loss: 0.955 | Val loss: 1.163 | Gen: etay airway ongingicay-awlay isway oroushhay\n",
      "Epoch:  12 | Train loss: 0.889 | Val loss: 1.145 | Gen: etay airway ongingineryway isway ordingway\n",
      "Epoch:  13 | Train loss: 0.861 | Val loss: 1.096 | Gen: etay airway ondingingscay isway ordingsway\n",
      "Epoch:  14 | Train loss: 0.817 | Val loss: 1.078 | Gen: etay airway ongingerinstay isway orkninway\n",
      "Epoch:  15 | Train loss: 0.784 | Val loss: 1.028 | Gen: etay airway onginghinedway isway oustinway\n",
      "Epoch:  16 | Train loss: 0.750 | Val loss: 1.067 | Gen: etay airway onginghionway isway orkingway\n",
      "Epoch:  17 | Train loss: 0.737 | Val loss: 1.047 | Gen: ethay airway ondingsticay isway orkingway\n",
      "Epoch:  18 | Train loss: 0.713 | Val loss: 1.011 | Gen: etay airway ondingcinghay isway oustinway\n",
      "Epoch:  19 | Train loss: 0.692 | Val loss: 1.058 | Gen: eterway airway ondingctionay isway orkingway\n",
      "Epoch:  20 | Train loss: 0.674 | Val loss: 1.017 | Gen: ethay airway oncingdray-inway isway orkingway\n",
      "Epoch:  21 | Train loss: 0.664 | Val loss: 0.969 | Gen: etay airway ontingicoryway isway orkingway\n",
      "Epoch:  22 | Train loss: 0.627 | Val loss: 0.928 | Gen: ethay airway ontingicay-ayday isway orkingway\n",
      "Epoch:  23 | Train loss: 0.594 | Val loss: 0.932 | Gen: eteway airway ondingcionway isway ousthay\n",
      "Epoch:  24 | Train loss: 0.577 | Val loss: 0.917 | Gen: ethay airway ontingidineway isway orkingway\n",
      "Epoch:  25 | Train loss: 0.559 | Val loss: 0.937 | Gen: ethay airway ondingcionway isway orkingway\n",
      "Epoch:  26 | Train loss: 0.561 | Val loss: 0.946 | Gen: ethay airway ondinginercay isway orkingway\n",
      "Epoch:  27 | Train loss: 0.532 | Val loss: 0.941 | Gen: ethay airway ondingciontway isway orkingway\n",
      "Epoch:  28 | Train loss: 0.531 | Val loss: 0.907 | Gen: ethay airway ontingicay-ady isway orkingway\n",
      "Epoch:  29 | Train loss: 0.516 | Val loss: 0.926 | Gen: ethay airway ondinginghay isway orkingway\n",
      "Epoch:  30 | Train loss: 0.499 | Val loss: 0.902 | Gen: ethay iarway ontingbay-akeclay isway orkingway\n",
      "Epoch:  31 | Train loss: 0.497 | Val loss: 0.909 | Gen: ethay airway ondingintercay isway orkingway\n",
      "Epoch:  32 | Train loss: 0.489 | Val loss: 0.863 | Gen: ethay airway ondingciondcay isway orkingway\n",
      "Epoch:  33 | Train loss: 0.457 | Val loss: 0.906 | Gen: ethay airway ondingcionway isway orkingway\n",
      "Epoch:  34 | Train loss: 0.457 | Val loss: 0.864 | Gen: ethay airway ondingscionway isway orkingway\n",
      "Epoch:  35 | Train loss: 0.438 | Val loss: 0.824 | Gen: ethay airway ondingciontway isway orkingway\n",
      "Epoch:  36 | Train loss: 0.426 | Val loss: 0.867 | Gen: ethay airway ondingchestay isway orkingway\n",
      "Epoch:  37 | Train loss: 0.444 | Val loss: 0.884 | Gen: ethay iarway onctiondireway isway orkingway\n",
      "Epoch:  38 | Train loss: 0.453 | Val loss: 0.909 | Gen: ethay airway ondingctionway isway orkingway\n",
      "Epoch:  39 | Train loss: 0.421 | Val loss: 0.824 | Gen: ethay airway ondictionday isway oushay-owway\n",
      "Epoch:  40 | Train loss: 0.397 | Val loss: 0.814 | Gen: ethay airway ondinginedcay isway orkingway\n",
      "Epoch:  41 | Train loss: 0.392 | Val loss: 0.802 | Gen: ethay airway ondictionay-ayday isway orkingway\n",
      "Epoch:  42 | Train loss: 0.386 | Val loss: 0.822 | Gen: ethay airway oncidingdmay isway orkingway\n",
      "Epoch:  43 | Train loss: 0.375 | Val loss: 0.806 | Gen: ethay irayway ondiginestray isway oushidway\n",
      "Epoch:  44 | Train loss: 0.371 | Val loss: 0.809 | Gen: ethay airway ondinginedcay isway orkingway\n",
      "Epoch:  45 | Train loss: 0.377 | Val loss: 0.791 | Gen: ethay iray ondingsciotway isway orkingway\n",
      "Epoch:  46 | Train loss: 0.356 | Val loss: 0.772 | Gen: ethay airway ondictiongray isway orkingway\n",
      "Epoch:  47 | Train loss: 0.346 | Val loss: 0.768 | Gen: ethay irayway ondictionday-ay isway orkingway\n",
      "Epoch:  48 | Train loss: 0.338 | Val loss: 0.816 | Gen: ethay irayway ondictionday-ay isway oudinsway\n",
      "Epoch:  49 | Train loss: 0.343 | Val loss: 0.804 | Gen: ethay irayway ondingscionway isway orkingway\n",
      "Obtained lowest validation loss of: 0.7682769942079105\n",
      "source:\t\tthe air conditioning is working \n",
      "translated:\tethay irayway ondingscionway isway orkingway\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = 'the air conditioning is working'\n",
    "\n",
    "rnn_args_l = AttrDict()\n",
    "args_dict = {\n",
    "              'data_file_name': 'pig_latin_large',\n",
    "              'cuda':True,\n",
    "              'nepochs':50,\n",
    "              'checkpoint_dir':\"checkpoints\",\n",
    "              'learning_rate':0.005,\n",
    "              'lr_decay':0.99,\n",
    "              'early_stopping_patience':10,\n",
    "              'batch_size':512,\n",
    "              'hidden_size':32,\n",
    "              'encoder_type': 'rnn', # options: rnn / transformer\n",
    "              'decoder_type': 'rnn', # options: rnn / rnn_attention / transformer\n",
    "              'attention_type': '',  # options: additive / scaled_dot\n",
    "}\n",
    "rnn_args_l.update(args_dict)\n",
    "\n",
    "print_opts(rnn_args_l)\n",
    "rnn_encode_l, rnn_decoder_l, rnn_losses_l = train(rnn_args_l)\n",
    "\n",
    "translated = translate_sentence(TEST_SENTENCE, rnn_encode_l, rnn_decoder_l, None, rnn_args_l)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01HsZ6EItc56"
   },
   "source": [
    "The code below plots the training and validation losses of each model, as a function of the number of gradient descent iterations. Consider if there are significant differences in the validation performance of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Qyk_9-Fwtekj",
    "outputId": "de71aee1-81f7-40fb-e439-0594038faeea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_loss_comparison_lstm(rnn_losses_s, rnn_losses_l, rnn_args_s, rnn_args_l, 'lstm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cE4ijaCzneAt"
   },
   "source": [
    "Select best performing model, and try translating different sentences by changing the variable TEST_SENTENCE. Identify a failure mode and briefly describe it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WrNnz8W1nULf",
    "outputId": "a2d8bf5f-6b54-4cfe-d472-e058697e256e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source:\t\tsmall words work but unnecessarily elongated expressions malfunction \n",
      "translated:\tlallmay ordsway orkway utbay ennisulerscay-ay ellay-ontedway ersindersicway alnficomplay\n"
     ]
    }
   ],
   "source": [
    "best_encoder = rnn_encode_l # Replace with rnn_losses_s or rnn_losses l\n",
    "best_decoder = rnn_decoder_l # etc.\n",
    "best_args = rnn_args_l\n",
    "\n",
    "TEST_SENTENCE = 'small words work but unnecessarily elongated expressions malfunction'\n",
    "translated = translate_sentence(TEST_SENTENCE, best_encoder, best_decoder, None, best_args)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWwA6OGqlaTq"
   },
   "source": [
    "# Part 2: Additive Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJSafHSAmu_w"
   },
   "source": [
    "## Step 1: Additive Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AdewEVSMo5jJ"
   },
   "outputs": [],
   "source": [
    "class AdditiveAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(AdditiveAttention, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # A two layer fully-connected network\n",
    "        # hidden_size*2 --> hidden_size, ReLU, hidden_size --> 1\n",
    "        self.attention_network = nn.Sequential(\n",
    "                                    nn.Linear(hidden_size*2, hidden_size),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(hidden_size, 1)\n",
    "                                 )\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        \"\"\"The forward pass of the additive attention mechanism.\n",
    "\n",
    "        Arguments:\n",
    "            queries: The current decoder hidden state. (batch_size x hidden_size)\n",
    "            keys: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "            values: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "\n",
    "        Returns:\n",
    "            context: weighted average of the values (batch_size x 1 x hidden_size)\n",
    "            attention_weights: Normalized attention weights for each encoder hidden state. (batch_size x seq_len x 1)\n",
    "\n",
    "            The attention_weights must be a softmax weighting over the seq_len annotations.\n",
    "        \"\"\"\n",
    "        batch_size = keys.size(0)\n",
    "        expanded_queries = queries.view(batch_size, -1, self.hidden_size).expand_as(keys)\n",
    "        concat_inputs = torch.cat([expanded_queries, keys], dim=2)\n",
    "        unnormalized_attention = self.attention_network(concat_inputs)\n",
    "        attention_weights = self.softmax(unnormalized_attention)\n",
    "        context = torch.bmm(attention_weights.transpose(2,1), values)\n",
    "        return context, attention_weights\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73_p8d5EmvOJ"
   },
   "source": [
    "## Step 2: RNN Additive Attention Decoder\n",
    "We will now implement a recurrent decoder that makes use of the additive attention mechanism. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJaABkXrpJSw"
   },
   "outputs": [],
   "source": [
    "class RNNAttentionDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, attention_type='scaled_dot'):\n",
    "        super(RNNAttentionDecoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "\n",
    "        self.rnn = MyLSTMCell(input_size=hidden_size*2, hidden_size=hidden_size)\n",
    "        if attention_type == 'additive':\n",
    "          self.attention = AdditiveAttention(hidden_size=hidden_size)\n",
    "        elif attention_type == 'scaled_dot':\n",
    "          self.attention = ScaledDotAttention(hidden_size=hidden_size)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "        \n",
    "    def forward(self, inputs, annotations, hidden_init, cell_init):\n",
    "        \"\"\"Forward pass of the attention-based decoder RNN.\n",
    "\n",
    "        Arguments:\n",
    "            inputs: Input token indexes across a batch for all the time step. (batch_size x decoder_seq_len)\n",
    "            annotations: The encoder hidden states for each step of the input.\n",
    "                         sequence. (batch_size x seq_len x hidden_size)\n",
    "            hidden_init: The final hidden states from the encoder, across a batch. (batch_size x hidden_size)\n",
    "            cell_init: The final cell states from the encoder, across a batch. (batch_size x hidden_size)\n",
    "\n",
    "        Returns:\n",
    "            output: Un-normalized scores for each token in the vocabulary, across a batch for all the decoding time steps. (batch_size x decoder_seq_len x vocab_size)\n",
    "            attentions: The stacked attention weights applied to the encoder annotations (batch_size x encoder_seq_len x decoder_seq_len)\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size, seq_len = inputs.size()\n",
    "        embed = self.embedding(inputs)  # batch_size x seq_len x hidden_size        \n",
    "\n",
    "        hiddens = []\n",
    "        attentions = []\n",
    "        h_prev = hidden_init\n",
    "        c_prev = cell_init\n",
    "\n",
    "        for i in range(seq_len):\n",
    "            embed_current = embed[:,i,:]  # Get the current time step, across the whole batch\n",
    "            context, attention_weights = self.attention(h_prev, annotations, annotations)  # batch_size x 1 x hidden_size\n",
    "            embed_and_context = torch.cat([embed_current, context.squeeze(1)], dim=1)  # batch_size x (2*hidden_size)\n",
    "            h_prev, c_prev = self.rnn(embed_and_context, h_prev, c_prev)  # batch_size x hidden_size            \n",
    "            \n",
    "            \n",
    "            hiddens.append(h_prev)\n",
    "            attentions.append(attention_weights)\n",
    "\n",
    "        hiddens = torch.stack(hiddens, dim=1) # batch_size x seq_len x hidden_size\n",
    "        attentions = torch.cat(attentions, dim=2) # batch_size x seq_len x seq_len\n",
    "        \n",
    "        output = self.out(hiddens)  # batch_size x seq_len x vocab_size\n",
    "        return output, attentions\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYPae08Io1Fi"
   },
   "source": [
    "## Step 3: Training and Analysis\n",
    "Train the following language model that uses a recurrent encoder, and a recurrent decoder that has an additive attention component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ke6t6rCezpZV",
    "outputId": "b865fb9c-2919-425c-c947-479112621259"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                                      Opts                                      \n",
      "--------------------------------------------------------------------------------\n",
      "                         data_file_name: pig_latin_small                        \n",
      "                                   cuda: 1                                      \n",
      "                                nepochs: 50                                     \n",
      "                         checkpoint_dir: checkpoints                            \n",
      "                          learning_rate: 0.005                                  \n",
      "                               lr_decay: 0.99                                   \n",
      "                early_stopping_patience: 10                                     \n",
      "                             batch_size: 64                                     \n",
      "                            hidden_size: 64                                     \n",
      "                           encoder_type: rnn                                    \n",
      "                           decoder_type: rnn_attention                          \n",
      "                         attention_type: additive                               \n",
      "================================================================================\n",
      "================================================================================\n",
      "                                   Data Stats                                   \n",
      "--------------------------------------------------------------------------------\n",
      "('leisurely', 'eisurelylay')\n",
      "('subsist', 'ubsistsay')\n",
      "('truth', 'uthtray')\n",
      "('supposition', 'uppositionsay')\n",
      "('discovering', 'iscoveringday')\n",
      "Num unique word pairs: 3198\n",
      "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
      "Vocab size: 29\n",
      "================================================================================\n",
      "Moved models to GPU!\n",
      "Epoch:   0 | Train loss: 2.062 | Val loss: 1.816 | Gen: encay irsay itionday incay olway\n",
      "Epoch:   1 | Train loss: 1.514 | Val loss: 1.591 | Gen: etay irway ingday-ingday isway odgay-onday\n",
      "Epoch:   2 | Train loss: 1.212 | Val loss: 1.387 | Gen: ehay irway incondedunday isway ordedway\n",
      "Epoch:   3 | Train loss: 1.025 | Val loss: 1.255 | Gen: ethay irway ingtiontionsway isway ondgay\n",
      "Epoch:   4 | Train loss: 0.853 | Val loss: 1.254 | Gen: ehtay arway ondingingioncay isway ondray-onday\n",
      "Epoch:   5 | Train loss: 0.731 | Val loss: 0.997 | Gen: ehay irway onconditingcay isway ordondgay\n",
      "Epoch:   6 | Train loss: 0.607 | Val loss: 1.026 | Gen: ehtay iray oningingingcay isway orndingway\n",
      "Epoch:   7 | Train loss: 0.511 | Val loss: 0.912 | Gen: ehtay iray ondincotioncay isway orvay-onday\n",
      "Epoch:   8 | Train loss: 0.421 | Val loss: 0.748 | Gen: ehay ariway onditingcingway isway orway-ingway\n",
      "Epoch:   9 | Train loss: 0.342 | Val loss: 0.691 | Gen: ethay airway onditioningcay isway orway-ignay\n",
      "Epoch:  10 | Train loss: 0.266 | Val loss: 0.654 | Gen: ehtay airway onditioningcay isway orway-ongway\n",
      "Epoch:  11 | Train loss: 0.218 | Val loss: 0.685 | Gen: ethay airway onditioningcay isway orway-igngway\n",
      "Epoch:  12 | Train loss: 0.201 | Val loss: 0.610 | Gen: ethay airway onditioniongay isway orkngway\n",
      "Epoch:  13 | Train loss: 0.190 | Val loss: 0.619 | Gen: ethay airway onditionicay isway orkingway\n",
      "Epoch:  14 | Train loss: 0.159 | Val loss: 0.550 | Gen: ethay airway onditionicingway isway orkingway\n",
      "Epoch:  15 | Train loss: 0.168 | Val loss: 0.558 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  16 | Train loss: 0.132 | Val loss: 0.685 | Gen: ethay airway ondionigingcay isway orkingway\n",
      "Epoch:  17 | Train loss: 0.128 | Val loss: 0.549 | Gen: ehtay airway onditionicangay isway orkingway\n",
      "Epoch:  18 | Train loss: 0.112 | Val loss: 0.422 | Gen: ethay airway ondititingcay isway orkingway\n",
      "Epoch:  19 | Train loss: 0.064 | Val loss: 0.359 | Gen: ethay airway onditionigncay isway orkingway\n",
      "Epoch:  20 | Train loss: 0.053 | Val loss: 0.465 | Gen: ethay airway ondiionigngcay isway orkingway\n",
      "Epoch:  21 | Train loss: 0.068 | Val loss: 0.379 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  22 | Train loss: 0.048 | Val loss: 0.406 | Gen: ethay airway onditionqucay isway orkingway\n",
      "Epoch:  23 | Train loss: 0.046 | Val loss: 0.348 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  24 | Train loss: 0.028 | Val loss: 0.321 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  25 | Train loss: 0.023 | Val loss: 0.377 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  26 | Train loss: 0.020 | Val loss: 0.360 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  27 | Train loss: 0.015 | Val loss: 0.315 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  28 | Train loss: 0.011 | Val loss: 0.314 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  29 | Train loss: 0.009 | Val loss: 0.305 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  30 | Train loss: 0.007 | Val loss: 0.308 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  31 | Train loss: 0.006 | Val loss: 0.310 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  32 | Train loss: 0.006 | Val loss: 0.313 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  33 | Train loss: 0.005 | Val loss: 0.315 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  34 | Train loss: 0.005 | Val loss: 0.316 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  35 | Train loss: 0.004 | Val loss: 0.318 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  36 | Train loss: 0.004 | Val loss: 0.319 | Gen: ethay airway onditionigncay isway orkingway\n",
      "Epoch:  37 | Train loss: 0.004 | Val loss: 0.319 | Gen: ethay airway onditionigncay isway orkingway\n",
      "Epoch:  38 | Train loss: 0.003 | Val loss: 0.320 | Gen: ethay airway onditionigncay isway orkingway\n",
      "Epoch:  39 | Train loss: 0.003 | Val loss: 0.321 | Gen: ethay airway onditionigncay isway orkingway\n",
      "Validation loss has not improved in 10 epochs, stopping early\n",
      "Obtained lowest validation loss of: 0.3052460122734117\n",
      "source:\t\tthe air conditioning is working \n",
      "translated:\tethay airway onditionigncay isway orkingway\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = 'the air conditioning is working'\n",
    "\n",
    "rnn_attn_args = AttrDict()\n",
    "args_dict = {\n",
    "              'data_file_name': 'pig_latin_small',\n",
    "              'cuda':True, \n",
    "              'nepochs':50, \n",
    "              'checkpoint_dir':\"checkpoints\", \n",
    "              'learning_rate':0.005,\n",
    "              'lr_decay':0.99,\n",
    "              'early_stopping_patience':10,\n",
    "              'batch_size':64, \n",
    "              'hidden_size':64, \n",
    "              'encoder_type': 'rnn', # options: rnn / transformer\n",
    "              'decoder_type': 'rnn_attention', # options: rnn / rnn_attention / transformer\n",
    "              'attention_type': 'additive',  # options: additive / scaled_dot\n",
    "}\n",
    "rnn_attn_args.update(args_dict)\n",
    "\n",
    "print_opts(rnn_attn_args)\n",
    "rnn_attn_encoder, rnn_attn_decoder, rnn_attn_losses = train(rnn_attn_args)\n",
    "\n",
    "translated = translate_sentence(TEST_SENTENCE, rnn_attn_encoder, rnn_attn_decoder, None, rnn_attn_args)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VNVKbLc0ACj_",
    "outputId": "e38f9bb6-4aec-43f5-c807-8d6f7872ee78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source:\t\tsmall words work but unnecessarily elongated expressions malfunction \n",
      "translated:\tallsmay ordsway orkway utbay unnecessarilyway elongatedway expressionsway alfunctionmay\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = 'small words work but unnecessarily elongated expressions malfunction'\n",
    "translated = translate_sentence(TEST_SENTENCE, rnn_attn_encoder, rnn_attn_decoder, None, rnn_attn_args)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kw_GOIvzo1ix"
   },
   "source": [
    "# Part 3: Scaled Dot Product Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xq7nhsEio1w-"
   },
   "source": [
    "## Step 1: Implement Dot-Product Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_j3oY3hqsJQ"
   },
   "outputs": [],
   "source": [
    "class ScaledDotAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(ScaledDotAttention, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.Q = nn.Linear(hidden_size, hidden_size)\n",
    "        self.K = nn.Linear(hidden_size, hidden_size)\n",
    "        self.V = nn.Linear(hidden_size, hidden_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.scaling_factor = torch.rsqrt(torch.tensor(self.hidden_size, dtype= torch.float))\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        \"\"\"The forward pass of the scaled dot attention mechanism.\n",
    "\n",
    "        Arguments:\n",
    "            queries: The current decoder hidden state, 2D or 3D tensor. (batch_size x (k) x hidden_size)\n",
    "            keys: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "            values: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "\n",
    "        Returns:\n",
    "            context: weighted average of the values (batch_size x k x hidden_size)\n",
    "            attention_weights: Normalized attention weights for each encoder hidden state. (batch_size x seq_len x 1)\n",
    "\n",
    "            The output must be a softmax weighting over the seq_len annotations.\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = queries.shape[0]\n",
    "        q = self.Q(queries.view(batch_size, -1, queries.shape[2]))\n",
    "        k = self.K(keys)\n",
    "        v = self.V(values)\n",
    "        unnormalized_attention = k @ q.transpose(2, 1) * self.scaling_factor\n",
    "        attention_weights = self.softmax(unnormalized_attention).transpose(2, 1)\n",
    "        context = attention_weights @ v\n",
    "        return context, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unReAOrjo113"
   },
   "source": [
    "## Step 2: Causal Dot-Product Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovigzQffrKqj"
   },
   "outputs": [],
   "source": [
    "class CausalScaledDotAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(CausalScaledDotAttention, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.neg_inf = torch.tensor(-1e7)\n",
    "\n",
    "        self.Q = nn.Linear(hidden_size, hidden_size)\n",
    "        self.K = nn.Linear(hidden_size, hidden_size)\n",
    "        self.V = nn.Linear(hidden_size, hidden_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.scaling_factor = torch.rsqrt(torch.tensor(self.hidden_size, dtype= torch.float))\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        \"\"\"The forward pass of the scaled dot attention mechanism.\n",
    "\n",
    "        Arguments:\n",
    "            queries: The current decoder hidden state, 2D or 3D tensor. (batch_size x (k) x hidden_size)\n",
    "            keys: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "            values: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "\n",
    "        Returns:\n",
    "            context: weighted average of the values (batch_size x k x hidden_size)\n",
    "            attention_weights: Normalized attention weights for each encoder hidden state. (batch_size x seq_len x 1)\n",
    "\n",
    "            The output must be a softmax weighting over the seq_len annotations.\n",
    "        \"\"\"\n",
    "\n",
    "        # ------------\n",
    "        # FILL THIS IN\n",
    "        # ------------\n",
    "        batch_size = queries.shape[0]\n",
    "        q = self.Q(queries.view(batch_size, -1, queries.shape[2]))\n",
    "        k = self.K(keys)\n",
    "        v = self.V(values)\n",
    "        unnormalized_attention = k @ q.transpose(2, 1) * self.scaling_factor\n",
    "        mask = ~torch.triu(unnormalized_attention).bool()\n",
    "        attention_weights = self.softmax(unnormalized_attention.masked_fill(mask, self.neg_inf)).transpose(2, 1)\n",
    "        context = attention_weights @ v\n",
    "        return context, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tcpUFKqo2Oi"
   },
   "source": [
    "## Step 3: Transformer Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3B-fWsarlVk"
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers, opts):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.opts = opts\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        \n",
    "        self.self_attentions = nn.ModuleList([ScaledDotAttention(\n",
    "                                    hidden_size=hidden_size, \n",
    "                                 ) for i in range(self.num_layers)])\n",
    "        self.attention_mlps = nn.ModuleList([nn.Sequential(\n",
    "                                    nn.Linear(hidden_size, hidden_size),\n",
    "                                    nn.ReLU(),\n",
    "                                 ) for i in range(self.num_layers)])\n",
    "\n",
    "        self.positional_encodings = self.create_positional_encodings()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass of the encoder RNN.\n",
    "\n",
    "        Arguments:\n",
    "            inputs: Input token indexes across a batch for all time steps in the sequence. (batch_size x seq_len)\n",
    "\n",
    "        Returns:\n",
    "            annotations: The hidden states computed at each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "            None: Used to conform to standard encoder return signature.\n",
    "            None: Used to conform to standard encoder return signature.        \n",
    "        \"\"\"\n",
    "        batch_size, seq_len = inputs.size()\n",
    "\n",
    "        encoded = self.embedding(inputs)  # batch_size x seq_len x hidden_size\n",
    "\n",
    "        # Add positinal embeddings from self.create_positional_encodings. (a'la https://arxiv.org/pdf/1706.03762.pdf, section 3.5)\n",
    "        encoded = encoded + self.positional_encodings[:seq_len]\n",
    "\n",
    "        annotations = encoded\n",
    "        for i in range(self.num_layers):\n",
    "            new_annotations, self_attention_weights = self.self_attentions[i](annotations, annotations, annotations)  # batch_size x seq_len x hidden_size\n",
    "            residual_annotations = annotations + new_annotations\n",
    "            new_annotations = self.attention_mlps[i](residual_annotations)\n",
    "            annotations = residual_annotations + new_annotations\n",
    "\n",
    "        # Transformer encoder does not have a last hidden or cell layer. \n",
    "        return annotations, None, None\n",
    "\n",
    "    def create_positional_encodings(self, max_seq_len=1000):\n",
    "        \"\"\"Creates positional encodings for the inputs.\n",
    "\n",
    "        Arguments:\n",
    "            max_seq_len: a number larger than the maximum string length we expect to encounter during training\n",
    "\n",
    "        Returns:\n",
    "            pos_encodings: (max_seq_len, hidden_dim) Positional encodings for a sequence with length max_seq_len. \n",
    "        \"\"\"\n",
    "        pos_indices = torch.arange(max_seq_len)[..., None]\n",
    "        dim_indices = torch.arange(self.hidden_size//2)[None, ...]\n",
    "        exponents = (2*dim_indices).float()/(self.hidden_size)\n",
    "        trig_args = pos_indices / (10000**exponents)\n",
    "        sin_terms = torch.sin(trig_args)\n",
    "        cos_terms = torch.cos(trig_args)\n",
    "\n",
    "        pos_encodings = torch.zeros((max_seq_len, self.hidden_size))\n",
    "        pos_encodings[:, 0::2] = sin_terms\n",
    "        pos_encodings[:, 1::2] = cos_terms\n",
    "\n",
    "        if self.opts.cuda:\n",
    "            pos_encodings = pos_encodings.cuda()\n",
    "\n",
    "        return pos_encodings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1hDi020rT36"
   },
   "source": [
    "## Step 4: Transformer Decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nyvTZFxtrvc6"
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)        \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.self_attentions = nn.ModuleList([CausalScaledDotAttention(\n",
    "                                    hidden_size=hidden_size, \n",
    "                                 ) for i in range(self.num_layers)])\n",
    "        self.encoder_attentions = nn.ModuleList([ScaledDotAttention(\n",
    "                                    hidden_size=hidden_size, \n",
    "                                 ) for i in range(self.num_layers)])\n",
    "        self.attention_mlps = nn.ModuleList([nn.Sequential(\n",
    "                                    nn.Linear(hidden_size, hidden_size),\n",
    "                                    nn.ReLU(),\n",
    "                                 ) for i in range(self.num_layers)])\n",
    "        self.out = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "        self.positional_encodings = self.create_positional_encodings()\n",
    "\n",
    "    def forward(self, inputs, annotations, hidden_init, cell_init):\n",
    "        \"\"\"Forward pass of the attention-based decoder RNN.\n",
    "\n",
    "        Arguments:\n",
    "            inputs: Input token indexes across a batch for all the time step. (batch_size x decoder_seq_len)\n",
    "            annotations: The encoder hidden states for each step of the input.\n",
    "                         sequence. (batch_size x seq_len x hidden_size)\n",
    "            hidden_init: Not used in the transformer decoder\n",
    "            cell_init: Not used in transformer decoder\n",
    "        Returns:\n",
    "            output: Un-normalized scores for each token in the vocabulary, across a batch for all the decoding time steps. (batch_size x decoder_seq_len x vocab_size)\n",
    "            attentions: The stacked attention weights applied to the encoder annotations (batch_size x encoder_seq_len x decoder_seq_len)\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size, seq_len = inputs.size()\n",
    "        embed = self.embedding(inputs)  # batch_size x seq_len x hidden_size\n",
    "\n",
    "        embed = embed + self.positional_encodings[:seq_len]\n",
    "\n",
    "        encoder_attention_weights_list = []\n",
    "        self_attention_weights_list = []\n",
    "        contexts = embed\n",
    "        for i in range(self.num_layers):\n",
    "            new_contexts, self_attention_weights = self.self_attentions[i](contexts, contexts, contexts)  # batch_size x seq_len x hidden_size\n",
    "            residual_contexts = contexts + new_contexts\n",
    "            new_contexts, encoder_attention_weights = self.encoder_attentions[i](residual_contexts, annotations, annotations) # batch_size x seq_len x hidden_size\n",
    "            residual_contexts = residual_contexts + new_contexts\n",
    "            new_contexts = self.attention_mlps[i](residual_contexts)\n",
    "            contexts = residual_contexts + new_contexts\n",
    "\n",
    "            encoder_attention_weights_list.append(encoder_attention_weights)\n",
    "            self_attention_weights_list.append(self_attention_weights)\n",
    "          \n",
    "        output = self.out(contexts)\n",
    "        encoder_attention_weights = torch.stack(encoder_attention_weights_list)\n",
    "        self_attention_weights = torch.stack(self_attention_weights_list)\n",
    "        \n",
    "        return output, (encoder_attention_weights, self_attention_weights)\n",
    "\n",
    "    def create_positional_encodings(self, max_seq_len=1000):\n",
    "        \"\"\"Creates positional encodings for the inputs.\n",
    "\n",
    "        Arguments:\n",
    "            max_seq_len: a number larger than the maximum string length we expect to encounter during training\n",
    "\n",
    "        Returns:\n",
    "            pos_encodings: (max_seq_len, hidden_dim) Positional encodings for a sequence with length max_seq_len. \n",
    "        \"\"\"\n",
    "        pos_indices = torch.arange(max_seq_len)[..., None]\n",
    "        dim_indices = torch.arange(self.hidden_size//2)[None, ...]\n",
    "        exponents = (2*dim_indices).float()/(self.hidden_size)\n",
    "        trig_args = pos_indices / (10000**exponents)\n",
    "        sin_terms = torch.sin(trig_args)\n",
    "        cos_terms = torch.cos(trig_args)\n",
    "\n",
    "        pos_encodings = torch.zeros((max_seq_len, self.hidden_size))\n",
    "        pos_encodings[:, 0::2] = sin_terms\n",
    "        pos_encodings[:, 1::2] = cos_terms\n",
    "\n",
    "        pos_encodings = pos_encodings.cuda()\n",
    "\n",
    "        return pos_encodings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29ZjkXTNrUKb"
   },
   "source": [
    "\n",
    "## Step 5: Training and analysis\n",
    "Now, train the following language model that's comprised of a (simplified) transformer encoder and transformer decoder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqTp-eCPuuFO"
   },
   "source": [
    "First, we train our smaller model on the small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mk8e4KSnuZ8N",
    "outputId": "b324ae2b-cefd-4a3e-f144-ed4c17bbd8ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                                      Opts                                      \n",
      "--------------------------------------------------------------------------------\n",
      "                         data_file_name: pig_latin_small                        \n",
      "                                   cuda: 1                                      \n",
      "                                nepochs: 100                                    \n",
      "                         checkpoint_dir: checkpoints                            \n",
      "                          learning_rate: 0.0005                                 \n",
      "                early_stopping_patience: 100                                    \n",
      "                               lr_decay: 0.99                                   \n",
      "                             batch_size: 64                                     \n",
      "                            hidden_size: 32                                     \n",
      "                           encoder_type: transformer                            \n",
      "                           decoder_type: transformer                            \n",
      "                 num_transformer_layers: 3                                      \n",
      "================================================================================\n",
      "================================================================================\n",
      "                                   Data Stats                                   \n",
      "--------------------------------------------------------------------------------\n",
      "('leisurely', 'eisurelylay')\n",
      "('subsist', 'ubsistsay')\n",
      "('truth', 'uthtray')\n",
      "('supposition', 'uppositionsay')\n",
      "('discovering', 'iscoveringday')\n",
      "Num unique word pairs: 3198\n",
      "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
      "Vocab size: 29\n",
      "================================================================================\n",
      "Moved models to GPU!\n",
      "Epoch:   0 | Train loss: 2.948 | Val loss: 2.479 | Gen: eay ieay ieoaiicccayay isayay oarayay\n",
      "Epoch:   1 | Train loss: 2.189 | Val loss: 2.118 | Gen: eday iway indandinday isisssssay onday\n",
      "Epoch:   2 | Train loss: 1.886 | Val loss: 1.910 | Gen: eeay aliway ondingdingay ississssay oncay-ongray\n",
      "Epoch:   3 | Train loss: 1.686 | Val loss: 1.795 | Gen: eay aliway oncingcingcangdwangd issiy oncay-ongray\n",
      "Epoch:   4 | Train loss: 1.548 | Val loss: 1.699 | Gen: ehay array oncingcingcangdway isssay ongingcray\n",
      "Epoch:   5 | Train loss: 1.435 | Val loss: 1.624 | Gen: ehay array oncingcingingcangdan issssay ongingray\n",
      "Epoch:   6 | Train loss: 1.335 | Val loss: 1.552 | Gen: ehay arrray oncingcongingcay isssssay oringingray\n",
      "Epoch:   7 | Train loss: 1.252 | Val loss: 1.536 | Gen: ehay arrray ondingingingcay issssay oringingray\n",
      "Epoch:   8 | Train loss: 1.182 | Val loss: 1.472 | Gen: ehay arrray ondingingingcay isssssw oringingray\n",
      "Epoch:   9 | Train loss: 1.117 | Val loss: 1.519 | Gen: ehay arrray oindingcatingcay issway ormingrray\n",
      "Epoch:  10 | Train loss: 1.065 | Val loss: 1.417 | Gen: ehay arrray ondingcatingway isssssay oringrrrray\n",
      "Epoch:  11 | Train loss: 1.006 | Val loss: 1.403 | Gen: ehay arrray ondingingingcatingdw isway ormrmrmray\n",
      "Epoch:  12 | Train loss: 0.958 | Val loss: 1.380 | Gen: ehay arrray ondingcatingway issway ormrmrmray\n",
      "Epoch:  13 | Train loss: 0.908 | Val loss: 1.366 | Gen: ehay arrray ondingcatingway isway orringrray-engrway\n",
      "Epoch:  14 | Train loss: 0.877 | Val loss: 1.377 | Gen: ethay arrway ondingingay-ongday isway ormrmrmray\n",
      "Epoch:  15 | Train loss: 0.831 | Val loss: 1.372 | Gen: ethay arrway ondingdingway-onding isway orkongrrway\n",
      "Epoch:  16 | Train loss: 0.810 | Val loss: 1.319 | Gen: ethay arrway ondingcandingway isway okrmrmrway\n",
      "Epoch:  17 | Train loss: 0.780 | Val loss: 1.292 | Gen: ethay arrway ondingdingdingctay isway orkongrmrway\n",
      "Epoch:  18 | Train loss: 0.749 | Val loss: 1.371 | Gen: ehthay arrway ondintingdingctiday isway okkrmrmrmay\n",
      "Epoch:  19 | Train loss: 0.722 | Val loss: 1.353 | Gen: ehay arrway ondingctingcrngday isway orkmrmmrmay\n",
      "Epoch:  20 | Train loss: 0.697 | Val loss: 1.215 | Gen: ehay arway odincitingcay isway okkrmrmrway\n",
      "Epoch:  21 | Train loss: 0.652 | Val loss: 1.242 | Gen: ehay arway ondingctingwingway isway okormngrway\n",
      "Epoch:  22 | Train loss: 0.643 | Val loss: 1.173 | Gen: ehay arway ondingctingwaxciting isway okkrmrmrway\n",
      "Epoch:  23 | Train loss: 0.604 | Val loss: 1.188 | Gen: ehay arrway odincingcingcay isway okrmrmrmway\n",
      "Epoch:  24 | Train loss: 0.570 | Val loss: 1.165 | Gen: ehay arway odintingcingway isway okormrmrway\n",
      "Epoch:  25 | Train loss: 0.537 | Val loss: 1.158 | Gen: ehay arrway odincingcingway isway okormmrway\n",
      "Epoch:  26 | Train loss: 0.514 | Val loss: 1.167 | Gen: ehay arrway odintingcay isway okrmrmrway\n",
      "Epoch:  27 | Train loss: 0.496 | Val loss: 1.169 | Gen: ehay arway ondiniongcingway isway okormrmway\n",
      "Epoch:  28 | Train loss: 0.478 | Val loss: 1.144 | Gen: ehay arrway oddiningcingcay isway okrmrmway\n",
      "Epoch:  29 | Train loss: 0.472 | Val loss: 1.291 | Gen: ehay arway ondimiongcay isway okormongway\n",
      "Epoch:  30 | Train loss: 0.477 | Val loss: 1.138 | Gen: ehay arway onditiongiongcay isway okrmrmway\n",
      "Epoch:  31 | Train loss: 0.445 | Val loss: 1.207 | Gen: ehay arway onditingcay isway okormrmway\n",
      "Epoch:  32 | Train loss: 0.438 | Val loss: 1.184 | Gen: ehay arway onditiongiongcay isway okrmrmrway\n",
      "Epoch:  33 | Train loss: 0.408 | Val loss: 1.241 | Gen: ehay arway onditiongiongway isway orkwingway\n",
      "Epoch:  34 | Train loss: 0.381 | Val loss: 1.306 | Gen: ehay arway onditiongiongway iway orkwingway\n",
      "Epoch:  35 | Train loss: 0.364 | Val loss: 1.275 | Gen: ehay arway onditiongiongway iway orkwingway\n",
      "Epoch:  36 | Train loss: 0.345 | Val loss: 1.246 | Gen: ehay arway onditiongiongway iway orkwingway\n",
      "Epoch:  37 | Train loss: 0.333 | Val loss: 1.237 | Gen: ehay arway onditiongiongway isway orkwingway\n",
      "Epoch:  38 | Train loss: 0.315 | Val loss: 1.151 | Gen: ethay arway onditiongiongway iway orkwingway\n",
      "Epoch:  39 | Train loss: 0.300 | Val loss: 1.122 | Gen: ethay arway onditiongiongway isway orkwingway\n",
      "Epoch:  40 | Train loss: 0.286 | Val loss: 1.134 | Gen: ethay arway onditiongiongway iway orkwingway\n",
      "Epoch:  41 | Train loss: 0.275 | Val loss: 1.087 | Gen: ethay arrway onditiongiongway isway orkwingway\n",
      "Epoch:  42 | Train loss: 0.263 | Val loss: 1.074 | Gen: ethay arway onditiongiongway isway orkwingway\n",
      "Epoch:  43 | Train loss: 0.257 | Val loss: 1.054 | Gen: ethay arrway onditiongiongway isway orkwingway\n",
      "Epoch:  44 | Train loss: 0.250 | Val loss: 1.046 | Gen: ethay arway onditiongiongway isway orkwingway\n",
      "Epoch:  45 | Train loss: 0.253 | Val loss: 1.089 | Gen: ethay arrway onditiongiongcay isway orkkway\n",
      "Epoch:  46 | Train loss: 0.258 | Val loss: 0.998 | Gen: ethay arrway onditiongiongcay isway orkwingway\n",
      "Epoch:  47 | Train loss: 0.234 | Val loss: 1.037 | Gen: ethay arrway onditiongiongway isway orkwingway\n",
      "Epoch:  48 | Train loss: 0.214 | Val loss: 1.020 | Gen: ethay arrway onditiongciongway isway orkkongrway\n",
      "Epoch:  49 | Train loss: 0.210 | Val loss: 1.004 | Gen: ethay arirway onditiongciongway isway orkingway\n",
      "Epoch:  50 | Train loss: 0.201 | Val loss: 1.001 | Gen: ethay arway onditiongciongway isway orkkwingway\n",
      "Epoch:  51 | Train loss: 0.194 | Val loss: 0.997 | Gen: ethay arirway onditiongciongway isway orkingway\n",
      "Epoch:  52 | Train loss: 0.189 | Val loss: 0.992 | Gen: ehtay arirway onditiongiongcay isway okkringway\n",
      "Epoch:  53 | Train loss: 0.188 | Val loss: 1.028 | Gen: ethay arirway onditiongiongcay isway okkringway\n",
      "Epoch:  54 | Train loss: 0.193 | Val loss: 1.002 | Gen: ethay arway onditingiongwingcay iway okkringway\n",
      "Epoch:  55 | Train loss: 0.198 | Val loss: 0.998 | Gen: ethay arirway onditiongciongway isway orkingway\n",
      "Epoch:  56 | Train loss: 0.175 | Val loss: 1.000 | Gen: ethay arway odnitiongciongway iway orkingway\n",
      "Epoch:  57 | Train loss: 0.168 | Val loss: 1.033 | Gen: ethay arway odditiongiongcay isway orkingway\n",
      "Epoch:  58 | Train loss: 0.194 | Val loss: 1.007 | Gen: ethay arway onditiongiongway iway okkwingway\n",
      "Epoch:  59 | Train loss: 0.172 | Val loss: 1.109 | Gen: ethay arway onditiongiongway isway okoringway\n",
      "Epoch:  60 | Train loss: 0.174 | Val loss: 1.054 | Gen: ethay arway onditiongiongway isway orkingway\n",
      "Epoch:  61 | Train loss: 0.153 | Val loss: 1.041 | Gen: ethay arway onditiongciongway isway okkringway\n",
      "Epoch:  62 | Train loss: 0.142 | Val loss: 1.012 | Gen: ethay arway ondditingiongway isway orkingway\n",
      "Epoch:  63 | Train loss: 0.136 | Val loss: 0.994 | Gen: ethay arway onditiongciongway isway okkringway\n",
      "Epoch:  64 | Train loss: 0.132 | Val loss: 1.004 | Gen: ethay arway onditiongciongway isway okkringway\n",
      "Epoch:  65 | Train loss: 0.128 | Val loss: 1.020 | Gen: ethay arway onditiongiongcay isway okkingway\n",
      "Epoch:  66 | Train loss: 0.124 | Val loss: 1.042 | Gen: ethay arway onditiongiongway isway okkingway\n",
      "Epoch:  67 | Train loss: 0.119 | Val loss: 1.063 | Gen: ethay arway onditiongiongway isway orkingway\n",
      "Epoch:  68 | Train loss: 0.116 | Val loss: 1.077 | Gen: ethay arway onditiongiongway isway orkingway\n",
      "Epoch:  69 | Train loss: 0.112 | Val loss: 1.073 | Gen: ethay arway onditiongiongway isway orkingway\n",
      "Epoch:  70 | Train loss: 0.109 | Val loss: 1.080 | Gen: ethay arway onditiongiongcay isway orkingway\n",
      "Epoch:  71 | Train loss: 0.105 | Val loss: 1.107 | Gen: ethay arway onditiongiongwiongwa isway orkingway\n",
      "Epoch:  72 | Train loss: 0.103 | Val loss: 1.084 | Gen: ethay arway onditiongiongcay isway orkingway\n",
      "Epoch:  73 | Train loss: 0.096 | Val loss: 1.100 | Gen: ethay arway onditiongiongcay isway orkingway\n",
      "Epoch:  74 | Train loss: 0.092 | Val loss: 1.113 | Gen: ethay arway onditiongiongcay isway orkingway\n",
      "Epoch:  75 | Train loss: 0.089 | Val loss: 1.132 | Gen: ethay arway onditiongiongcay isway orkingway\n",
      "Epoch:  76 | Train loss: 0.087 | Val loss: 1.137 | Gen: ethay arway onditiongiongcay isway orkingway\n",
      "Epoch:  77 | Train loss: 0.099 | Val loss: 1.241 | Gen: ethay arway onditiongiongcay isway orkingway\n",
      "Epoch:  78 | Train loss: 0.193 | Val loss: 1.182 | Gen: ethay arway oddimioningixctidgay isway okwingway\n",
      "Epoch:  79 | Train loss: 0.201 | Val loss: 1.192 | Gen: ethay arway onditioniiingwigwigw isway orkingway\n",
      "Epoch:  80 | Train loss: 0.197 | Val loss: 1.052 | Gen: ethay arway onditiongingway isway orkingway\n",
      "Epoch:  81 | Train loss: 0.143 | Val loss: 1.010 | Gen: ethay arway onditioniongcay isway orkingway\n",
      "Epoch:  82 | Train loss: 0.116 | Val loss: 1.031 | Gen: ethay arway onditiongiongway isway orkingway\n",
      "Epoch:  83 | Train loss: 0.095 | Val loss: 1.112 | Gen: ethay arway onditiongiongcay isway orkingway\n",
      "Epoch:  84 | Train loss: 0.088 | Val loss: 1.135 | Gen: ethay arway onditiongiongcay isway orkingway\n",
      "Epoch:  85 | Train loss: 0.082 | Val loss: 1.110 | Gen: ethay arway onditiongingcay isway orkingway\n",
      "Epoch:  86 | Train loss: 0.076 | Val loss: 1.111 | Gen: ethay arway onditiongingway isway orkingway\n",
      "Epoch:  87 | Train loss: 0.072 | Val loss: 1.111 | Gen: ethay arway onditiongingcay isway orkingway\n",
      "Epoch:  88 | Train loss: 0.068 | Val loss: 1.117 | Gen: ethay arway onditiongingcay isway orkingway\n",
      "Epoch:  89 | Train loss: 0.065 | Val loss: 1.124 | Gen: ethay arway onditiongingcay isway orkingway\n",
      "Epoch:  90 | Train loss: 0.062 | Val loss: 1.129 | Gen: ethay arway onditiongingcay isway orkingway\n",
      "Epoch:  91 | Train loss: 0.060 | Val loss: 1.136 | Gen: ethay arway onditiongingcay isway orkingway\n",
      "Epoch:  92 | Train loss: 0.058 | Val loss: 1.143 | Gen: ethay arway onditiongingcay isway orkingway\n",
      "Epoch:  93 | Train loss: 0.056 | Val loss: 1.153 | Gen: ethay arway onditiongingcay isway orkingway\n",
      "Epoch:  94 | Train loss: 0.054 | Val loss: 1.162 | Gen: ethay arway onditiongingcay isway orkingway\n",
      "Epoch:  95 | Train loss: 0.052 | Val loss: 1.171 | Gen: ethay arway onditiongingcay isway orkingway\n",
      "Epoch:  96 | Train loss: 0.051 | Val loss: 1.180 | Gen: ethay arway onditiongingcay isway orkingway\n",
      "Epoch:  97 | Train loss: 0.049 | Val loss: 1.190 | Gen: ethay arway onditiongingcay isway orkingway\n",
      "Epoch:  98 | Train loss: 0.047 | Val loss: 1.199 | Gen: ethay arway onditiongingcay isway orkingway\n",
      "Epoch:  99 | Train loss: 0.046 | Val loss: 1.208 | Gen: ethay arway onditiongingcay isway orkingway\n",
      "Obtained lowest validation loss of: 0.9923313451118958\n",
      "source:\t\tthe air conditioning is working \n",
      "translated:\tethay arway onditiongingcay isway orkingway\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = 'the air conditioning is working'\n",
    "\n",
    "trans32_args_s = AttrDict()\n",
    "args_dict = {\n",
    "              'data_file_name': 'pig_latin_small',\n",
    "              'cuda':True, \n",
    "              'nepochs':100, \n",
    "              'checkpoint_dir':\"checkpoints\", \n",
    "              'learning_rate':5e-4,\n",
    "              'early_stopping_patience': 100,\n",
    "              'lr_decay':0.99,\n",
    "              'batch_size': 64,\n",
    "              'hidden_size': 32,\n",
    "              'encoder_type': 'transformer',\n",
    "              'decoder_type': 'transformer', # options: rnn / rnn_attention / transformer\n",
    "              'num_transformer_layers': 3,\n",
    "}\n",
    "trans32_args_s.update(args_dict)\n",
    "print_opts(trans32_args_s)\n",
    "\n",
    "trans32_encoder_s, trans32_decoder_s, trans32_losses_s = train(trans32_args_s)\n",
    "\n",
    "translated = translate_sentence(TEST_SENTENCE, trans32_encoder_s, trans32_decoder_s, None, trans32_args_s)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l28mKuZxvaRT",
    "outputId": "e5d9fa04-1c5b-4b81-f8fb-845c871490c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source:\t\tthe air conditioning is working \n",
      "translated:\tethay arway onditiongingcay isway orkingway\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = 'the air conditioning is working'\n",
    "translated = translate_sentence(TEST_SENTENCE, trans32_encoder_s, trans32_decoder_s, None, trans32_args_s)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0L8EqLYFu48H"
   },
   "source": [
    "In the following cells, we investigate the effects of increasing model size and dataset size on the training / validation curves and generalization of the Transformer. We will increase hidden size to 64, and also increase dataset size. Include the best achieved validation loss in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FdZO69DozuUu",
    "outputId": "563b7e3a-a601-4314-9070-8d62c99e17e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                                      Opts                                      \n",
      "--------------------------------------------------------------------------------\n",
      "                         data_file_name: pig_latin_large                        \n",
      "                                   cuda: 1                                      \n",
      "                                nepochs: 100                                    \n",
      "                         checkpoint_dir: checkpoints                            \n",
      "                          learning_rate: 0.0005                                 \n",
      "                early_stopping_patience: 10                                     \n",
      "                               lr_decay: 0.99                                   \n",
      "                             batch_size: 512                                    \n",
      "                            hidden_size: 32                                     \n",
      "                           encoder_type: transformer                            \n",
      "                           decoder_type: transformer                            \n",
      "                 num_transformer_layers: 3                                      \n",
      "================================================================================\n",
      "================================================================================\n",
      "                                   Data Stats                                   \n",
      "--------------------------------------------------------------------------------\n",
      "('albuquerque', 'albuquerqueway')\n",
      "('ejaculation', 'ejaculationway')\n",
      "('kenwood', 'enwoodkay')\n",
      "('satire', 'atiresay')\n",
      "('rite', 'iteray')\n",
      "Num unique word pairs: 22402\n",
      "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
      "Vocab size: 29\n",
      "================================================================================\n",
      "Moved models to GPU!\n",
      "Epoch:   0 | Train loss: 2.601 | Val loss: 2.268 | Gen: ay-ay-ay--ay-ay-ay-a iiiininininininiay oiay-ay iiiiiiiiiiiiiiiiiway -----------ay---ay-a\n",
      "Epoch:   1 | Train loss: 2.028 | Val loss: 1.978 | Gen: ay-ay-ay inway iatintintintintay iiiiwy oinsay-ay-ay-ay-ay\n",
      "Epoch:   2 | Train loss: 1.820 | Val loss: 1.853 | Gen: etay iaway otintintintintintay iiway onray-ay-ay-ay\n",
      "Epoch:   3 | Train loss: 1.668 | Val loss: 1.809 | Gen: ethay iay iotintintintintintin iway insay-insay\n",
      "Epoch:   4 | Train loss: 1.581 | Val loss: 1.713 | Gen: ethay-ay arway ontintintinway isiway oray-oray\n",
      "Epoch:   5 | Train loss: 1.492 | Val loss: 1.650 | Gen: ethay arway ontintinsay-onway iway oray-oray\n",
      "Epoch:   6 | Train loss: 1.391 | Val loss: 1.611 | Gen: ethay arway ontinsay-onway-onway isiway orrineay\n",
      "Epoch:   7 | Train loss: 1.327 | Val loss: 1.583 | Gen: ethay aray oofortionononsay iway orringay\n",
      "Epoch:   8 | Train loss: 1.277 | Val loss: 1.542 | Gen: ethay arirway iofiniontionionway isway irrray\n",
      "Epoch:   9 | Train loss: 1.223 | Val loss: 1.535 | Gen: ethay aray oninsiominsay isway orrray\n",
      "Epoch:  10 | Train loss: 1.199 | Val loss: 1.433 | Gen: ethay arirway ontinway-ionway isway orrrway\n",
      "Epoch:  11 | Train loss: 1.130 | Val loss: 1.432 | Gen: ethay aray ontinstinstinway iway orrrway\n",
      "Epoch:  12 | Train loss: 1.075 | Val loss: 1.447 | Gen: thahay ariray ontionway-ionway isway orrrway-ay\n",
      "Epoch:  13 | Train loss: 1.044 | Val loss: 1.355 | Gen: ethay aray ontingmatingngay iway orrway\n",
      "Epoch:  14 | Train loss: 0.984 | Val loss: 1.268 | Gen: ethay ariray ondonticiongngay isway orkrkay\n",
      "Epoch:  15 | Train loss: 0.946 | Val loss: 1.278 | Gen: ethay aray ondonimtingngay isway orkingay\n",
      "Epoch:  16 | Train loss: 0.916 | Val loss: 1.237 | Gen: ethay ariray ondintionstinway isway orkingay\n",
      "Epoch:  17 | Train loss: 0.895 | Val loss: 1.226 | Gen: ethay arway ondnitictiongngngway isway orkingay\n",
      "Epoch:  18 | Train loss: 0.868 | Val loss: 1.185 | Gen: ethay ariray ondinctiongngngay isway orkingay\n",
      "Epoch:  19 | Train loss: 0.830 | Val loss: 1.207 | Gen: ethay ariray ondniniongmay isway orkingay\n",
      "Epoch:  20 | Train loss: 0.804 | Val loss: 1.164 | Gen: ethay ariray ondningingcatingngwa isway orkingay\n",
      "Epoch:  21 | Train loss: 0.771 | Val loss: 1.134 | Gen: ethay arway ondniongciongngay isway orkingay\n",
      "Epoch:  22 | Train loss: 0.755 | Val loss: 1.109 | Gen: ethay arway onndingiongngngnway isway orkingray\n",
      "Epoch:  23 | Train loss: 0.721 | Val loss: 1.126 | Gen: ehay arway ondnionicationgngway isway orkingay\n",
      "Epoch:  24 | Train loss: 0.716 | Val loss: 1.077 | Gen: ethay arway onndiontingngngngay isway orkingray\n",
      "Epoch:  25 | Train loss: 0.688 | Val loss: 1.107 | Gen: ethay arway ondningcatingngway isway orkingway\n",
      "Epoch:  26 | Train loss: 0.668 | Val loss: 1.047 | Gen: ethay arway ondindiongngngngay isway orkingray\n",
      "Epoch:  27 | Train loss: 0.639 | Val loss: 1.047 | Gen: ethay arway ondindiongngngngay isway orkingway\n",
      "Epoch:  28 | Train loss: 0.625 | Val loss: 0.976 | Gen: ethay arway ondindiontingngnway isway orkingray\n",
      "Epoch:  29 | Train loss: 0.605 | Val loss: 1.035 | Gen: ethay arway ondidingcangingngay isway orkingray\n",
      "Epoch:  30 | Train loss: 0.592 | Val loss: 0.967 | Gen: ethay arway ondictingcay isway orkingray\n",
      "Epoch:  31 | Train loss: 0.572 | Val loss: 1.034 | Gen: ethay arway ondditiongcangay isway orkirkangway\n",
      "Epoch:  32 | Train loss: 0.583 | Val loss: 0.989 | Gen: hhay ariray ondictiongngway isway orkingway\n",
      "Epoch:  33 | Train loss: 0.567 | Val loss: 0.985 | Gen: ethay arway ondidicayingway isway orkirkay\n",
      "Epoch:  34 | Train loss: 0.568 | Val loss: 0.960 | Gen: hhhay ariray onditicray isway orkirkway\n",
      "Epoch:  35 | Train loss: 0.546 | Val loss: 0.971 | Gen: ethay arway onditicay isway orkingway\n",
      "Epoch:  36 | Train loss: 0.536 | Val loss: 0.931 | Gen: ethay arway ondictiongngway isway orkingway\n",
      "Epoch:  37 | Train loss: 0.501 | Val loss: 0.898 | Gen: ethay ariray onditiongwiway isway orkirkway\n",
      "Epoch:  38 | Train loss: 0.486 | Val loss: 0.881 | Gen: ethay arway onditiongway isway orkingway\n",
      "Epoch:  39 | Train loss: 0.479 | Val loss: 0.853 | Gen: ethway ariray ondictiongngway isway orkingway\n",
      "Epoch:  40 | Train loss: 0.477 | Val loss: 0.926 | Gen: hhay arway onditioncingway isay orkingway\n",
      "Epoch:  41 | Train loss: 0.490 | Val loss: 0.883 | Gen: ethay airway onditiongway isway orkirkngway\n",
      "Epoch:  42 | Train loss: 0.460 | Val loss: 0.810 | Gen: hhay ariray onditiongway isway orkingway\n",
      "Epoch:  43 | Train loss: 0.450 | Val loss: 0.805 | Gen: hhthay ariray onditiongway isway orkingway\n",
      "Epoch:  44 | Train loss: 0.446 | Val loss: 0.774 | Gen: ethay ariray onditioncingngway isway orkingray\n",
      "Epoch:  45 | Train loss: 0.415 | Val loss: 0.774 | Gen: ethay arirway onditiongngway isway orkingray\n",
      "Epoch:  46 | Train loss: 0.408 | Val loss: 0.744 | Gen: ethay ariray onditiongngway isway orkingway\n",
      "Epoch:  47 | Train loss: 0.397 | Val loss: 0.798 | Gen: hthay arirway onditiongngway isway orkingray\n",
      "Epoch:  48 | Train loss: 0.386 | Val loss: 0.747 | Gen: hthay airway onditiongngway isway orkingray\n",
      "Epoch:  49 | Train loss: 0.374 | Val loss: 0.762 | Gen: hthay arirway onditioncingngway isway orkingway\n",
      "Epoch:  50 | Train loss: 0.372 | Val loss: 0.758 | Gen: ethway arirway onditiongngway isway orkingray\n",
      "Epoch:  51 | Train loss: 0.368 | Val loss: 0.722 | Gen: ethay airway onditiongngngway isway orkingway\n",
      "Epoch:  52 | Train loss: 0.357 | Val loss: 0.804 | Gen: hthay arirway onditioncingngway isway orkingray\n",
      "Epoch:  53 | Train loss: 0.352 | Val loss: 0.699 | Gen: ethay airway onditiongngway isway orkingway\n",
      "Epoch:  54 | Train loss: 0.336 | Val loss: 0.744 | Gen: hthay airway onditiongngway isway orkingray\n",
      "Epoch:  55 | Train loss: 0.336 | Val loss: 0.700 | Gen: ethay airway onditiongngway isway orkingway\n",
      "Epoch:  56 | Train loss: 0.325 | Val loss: 0.740 | Gen: hteway airway onditioncingngway isway orkingray\n",
      "Epoch:  57 | Train loss: 0.322 | Val loss: 0.690 | Gen: ethay airway onditioncingngway isway orkingway\n",
      "Epoch:  58 | Train loss: 0.326 | Val loss: 0.730 | Gen: hteway arirway onditiongngsay isway orkingway\n",
      "Epoch:  59 | Train loss: 0.354 | Val loss: 0.850 | Gen: ethay airway onditioncngngway isway orkingray\n",
      "Epoch:  60 | Train loss: 0.385 | Val loss: 0.841 | Gen: hteway ariwway onditioncngngway isway orkingway\n",
      "Epoch:  61 | Train loss: 0.342 | Val loss: 0.705 | Gen: ethay airway onditioncingngngway isway orkingway\n",
      "Epoch:  62 | Train loss: 0.314 | Val loss: 0.689 | Gen: hethay ariwway onditiongngingway isway orkingway\n",
      "Epoch:  63 | Train loss: 0.299 | Val loss: 0.656 | Gen: ethay airway onditiongngway isway orkingway\n",
      "Epoch:  64 | Train loss: 0.290 | Val loss: 0.684 | Gen: hethay airway onditioncingngway issway orkingray\n",
      "Epoch:  65 | Train loss: 0.289 | Val loss: 0.615 | Gen: ethay airway onditiongngway isway orkingway\n",
      "Epoch:  66 | Train loss: 0.271 | Val loss: 0.640 | Gen: ethay airway onditiongngway isway orkingway\n",
      "Epoch:  67 | Train loss: 0.265 | Val loss: 0.604 | Gen: ethay airway onditiongngway isway orkingway\n",
      "Epoch:  68 | Train loss: 0.254 | Val loss: 0.626 | Gen: ethay airway onditiongngway isway orkingway\n",
      "Epoch:  69 | Train loss: 0.253 | Val loss: 0.595 | Gen: ethay airway onditiongngway isway orkingway\n",
      "Epoch:  70 | Train loss: 0.245 | Val loss: 0.620 | Gen: ethay airway onditiongngcay isway orkingway\n",
      "Epoch:  71 | Train loss: 0.247 | Val loss: 0.589 | Gen: ethay airway onditiongngway isway orkingway\n",
      "Epoch:  72 | Train loss: 0.241 | Val loss: 0.622 | Gen: ethay ariway onditiongngcay issway orkingway\n",
      "Epoch:  73 | Train loss: 0.245 | Val loss: 0.578 | Gen: ethay airway onditiongngcay isway orkingway\n",
      "Epoch:  74 | Train loss: 0.233 | Val loss: 0.598 | Gen: ethay ariway onditiongngingway isway orkingray\n",
      "Epoch:  75 | Train loss: 0.227 | Val loss: 0.646 | Gen: ethay airway onditiongngingway isway orkingway\n",
      "Epoch:  76 | Train loss: 0.246 | Val loss: 0.641 | Gen: hteway ariway onditiongngcay isway orkingray\n",
      "Epoch:  77 | Train loss: 0.242 | Val loss: 0.577 | Gen: ethay ariway onditioncingway isway orkingway\n",
      "Epoch:  78 | Train loss: 0.217 | Val loss: 0.582 | Gen: ethay airway onditioncingngway isway orkingway\n",
      "Epoch:  79 | Train loss: 0.211 | Val loss: 0.566 | Gen: ethay airway onditiongngcay isway orkingway\n",
      "Epoch:  80 | Train loss: 0.204 | Val loss: 0.578 | Gen: ethay airway onditiongcingway isway orkingway\n",
      "Epoch:  81 | Train loss: 0.207 | Val loss: 0.565 | Gen: ethay ariway onditiongngcay isway orkingway\n",
      "Epoch:  82 | Train loss: 0.214 | Val loss: 0.711 | Gen: ethay airwway onditiongngingngway issway orkingway\n",
      "Epoch:  83 | Train loss: 0.273 | Val loss: 0.635 | Gen: hthay ariway onditioncingngway isway orkingway\n",
      "Epoch:  84 | Train loss: 0.244 | Val loss: 0.606 | Gen: ethay ariway onditioncingway isway orkingway\n",
      "Epoch:  85 | Train loss: 0.225 | Val loss: 0.569 | Gen: ethay airway onditiongcingway isway orkingway\n",
      "Epoch:  86 | Train loss: 0.207 | Val loss: 0.597 | Gen: ethay airway onditioncongngngway isway orkingway\n",
      "Epoch:  87 | Train loss: 0.199 | Val loss: 0.534 | Gen: ethay airway onditiongncay isway orkingway\n",
      "Epoch:  88 | Train loss: 0.206 | Val loss: 0.539 | Gen: ethay airway onditiongngingway isway orkingway\n",
      "Epoch:  89 | Train loss: 0.197 | Val loss: 0.557 | Gen: ethay airway onditiongncay isway orkingway\n",
      "Epoch:  90 | Train loss: 0.179 | Val loss: 0.540 | Gen: ethay airway onditiongcingway isway orkingway\n",
      "Epoch:  91 | Train loss: 0.173 | Val loss: 0.529 | Gen: ethay airway onditiongcingway isway orkingway\n",
      "Epoch:  92 | Train loss: 0.170 | Val loss: 0.539 | Gen: ethay airway onditiongcingway isway orkingway\n",
      "Epoch:  93 | Train loss: 0.166 | Val loss: 0.524 | Gen: ethay airway onditiongcingway isway orkingway\n",
      "Epoch:  94 | Train loss: 0.160 | Val loss: 0.534 | Gen: ethay airway onditiongcingway isway orkingway\n",
      "Epoch:  95 | Train loss: 0.158 | Val loss: 0.522 | Gen: ethay airway onditiongcingway isway orkingway\n",
      "Epoch:  96 | Train loss: 0.153 | Val loss: 0.529 | Gen: ethay airway onditiongcingway isway orkingway\n",
      "Epoch:  97 | Train loss: 0.150 | Val loss: 0.520 | Gen: ethay airway onditiongcingway isway orkingway\n",
      "Epoch:  98 | Train loss: 0.146 | Val loss: 0.522 | Gen: ethay airway onditiongcingway isway orkingway\n",
      "Epoch:  99 | Train loss: 0.144 | Val loss: 0.517 | Gen: ethay airway onditiongcingway isway orkingway\n",
      "Obtained lowest validation loss of: 0.5169435579183639\n",
      "source:\t\tthe air conditioning is working \n",
      "translated:\tethay airway onditiongcingway isway orkingway\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = 'the air conditioning is working'\n",
    "\n",
    "trans32_args_l = AttrDict()\n",
    "args_dict = {\n",
    "              'data_file_name': 'pig_latin_large', # Increased data set size\n",
    "              'cuda':True, \n",
    "              'nepochs':100,\n",
    "              'checkpoint_dir':\"checkpoints\", \n",
    "              'learning_rate':5e-4,\n",
    "              'early_stopping_patience': 10,\n",
    "              'lr_decay':0.99,\n",
    "              'batch_size': 512,\n",
    "              'hidden_size': 32,\n",
    "              'encoder_type': 'transformer',\n",
    "              'decoder_type': 'transformer', # options: rnn / rnn_attention / transformer\n",
    "              'num_transformer_layers': 3,\n",
    "}\n",
    "trans32_args_l.update(args_dict)\n",
    "print_opts(trans32_args_l)\n",
    "\n",
    "trans32_encoder_l, trans32_decoder_l, trans32_losses_l = train(trans32_args_l)\n",
    "\n",
    "translated = translate_sentence(TEST_SENTENCE, trans32_encoder_l, trans32_decoder_l, None, trans32_args_l)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmoTgrDcr_dw",
    "outputId": "cd2f088b-f11d-4b61-e930-fba9de5130c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                                      Opts                                      \n",
      "--------------------------------------------------------------------------------\n",
      "                         data_file_name: pig_latin_small                        \n",
      "                                   cuda: 1                                      \n",
      "                                nepochs: 50                                     \n",
      "                         checkpoint_dir: checkpoints                            \n",
      "                          learning_rate: 0.0005                                 \n",
      "                early_stopping_patience: 20                                     \n",
      "                               lr_decay: 0.99                                   \n",
      "                             batch_size: 64                                     \n",
      "                            hidden_size: 64                                     \n",
      "                           encoder_type: transformer                            \n",
      "                           decoder_type: transformer                            \n",
      "                 num_transformer_layers: 3                                      \n",
      "================================================================================\n",
      "================================================================================\n",
      "                                   Data Stats                                   \n",
      "--------------------------------------------------------------------------------\n",
      "('leisurely', 'eisurelylay')\n",
      "('subsist', 'ubsistsay')\n",
      "('truth', 'uthtray')\n",
      "('supposition', 'uppositionsay')\n",
      "('discovering', 'iscoveringday')\n",
      "Num unique word pairs: 3198\n",
      "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
      "Vocab size: 29\n",
      "================================================================================\n",
      "Moved models to GPU!\n",
      "Epoch:   0 | Train loss: 2.419 | Val loss: 1.996 | Gen: ay ay oncay isway ongay\n",
      "Epoch:   1 | Train loss: 1.666 | Val loss: 1.708 | Gen: ay aray indncincincay isway oungway\n",
      "Epoch:   2 | Train loss: 1.408 | Val loss: 1.597 | Gen: ay aray indintingay isway oungway\n",
      "Epoch:   3 | Train loss: 1.249 | Val loss: 1.445 | Gen: ethhhhay irway ondintinnngongonnnnc isway orkingway\n",
      "Epoch:   4 | Train loss: 1.104 | Val loss: 1.366 | Gen: ethhay aray indincintingoncinnci isway oungway\n",
      "Epoch:   5 | Train loss: 0.955 | Val loss: 1.305 | Gen: ethhay arway ondintingingiongay isway ouringway\n",
      "Epoch:   6 | Train loss: 0.861 | Val loss: 1.180 | Gen: ehthay arway ondintingingiongingi isway oringway\n",
      "Epoch:   7 | Train loss: 0.740 | Val loss: 1.108 | Gen: ehay arway ondintingongoooay isway orkingway\n",
      "Epoch:   8 | Train loss: 0.678 | Val loss: 1.143 | Gen: ehay arway ondintingway isway orkingway\n",
      "Epoch:   9 | Train loss: 0.642 | Val loss: 1.158 | Gen: etheway arway onndiontingcay isway orkingway\n",
      "Epoch:  10 | Train loss: 0.562 | Val loss: 0.973 | Gen: ethay arway ondintiongcay isway orkingway\n",
      "Epoch:  11 | Train loss: 0.470 | Val loss: 1.016 | Gen: etehay arway ondiontiongway isway orkingway\n",
      "Epoch:  12 | Train loss: 0.434 | Val loss: 1.026 | Gen: ethay arway onditionicay isway oringway\n",
      "Epoch:  13 | Train loss: 0.413 | Val loss: 0.903 | Gen: ehthay ariway onditioniongcay isway oringway\n",
      "Epoch:  14 | Train loss: 0.349 | Val loss: 0.908 | Gen: ehay arway ondiingciongiiiiingw isway oringway\n",
      "Epoch:  15 | Train loss: 0.299 | Val loss: 0.970 | Gen: ethay arway onidintioniongcay isway oringway\n",
      "Epoch:  16 | Train loss: 0.272 | Val loss: 0.839 | Gen: ethay arway onidintioniongway isway oringway\n",
      "Epoch:  17 | Train loss: 0.252 | Val loss: 1.008 | Gen: ethay aray onditionionicay isway orkingway\n",
      "Epoch:  18 | Train loss: 0.307 | Val loss: 0.979 | Gen: ethay arway oninitionionioncay isway orinkgway\n",
      "Epoch:  19 | Train loss: 0.316 | Val loss: 0.994 | Gen: ehay ay onditiongcay isway oringway\n",
      "Epoch:  20 | Train loss: 0.329 | Val loss: 0.869 | Gen: ethewhay ariway onnitionioniiinciy isway oringway\n",
      "Epoch:  21 | Train loss: 0.272 | Val loss: 0.807 | Gen: etay arway onditinioningcay isway oringway\n",
      "Epoch:  22 | Train loss: 0.194 | Val loss: 0.736 | Gen: ethay arway ondintioningcay isway oringway\n",
      "Epoch:  23 | Train loss: 0.149 | Val loss: 0.706 | Gen: ethay arway onditioningcay isway oringway\n",
      "Epoch:  24 | Train loss: 0.118 | Val loss: 0.699 | Gen: ethay arway onditioningcay isway oringway\n",
      "Epoch:  25 | Train loss: 0.099 | Val loss: 0.689 | Gen: ethay arway onditioningcay isway oringway\n",
      "Epoch:  26 | Train loss: 0.086 | Val loss: 0.702 | Gen: ethay arway onditioningcay isway oringway\n",
      "Epoch:  27 | Train loss: 0.072 | Val loss: 0.684 | Gen: ethay arway onditioningcay isway oringway\n",
      "Epoch:  28 | Train loss: 0.063 | Val loss: 0.690 | Gen: ethay arway onditioningcay isway oringway\n",
      "Epoch:  29 | Train loss: 0.056 | Val loss: 0.725 | Gen: ethay airway onditioningcay isway oringway\n",
      "Epoch:  30 | Train loss: 0.055 | Val loss: 0.775 | Gen: ethay airway onditioningcay isway oringway\n",
      "Epoch:  31 | Train loss: 0.055 | Val loss: 0.807 | Gen: ethay aiway onditioniongcay isway orkingway\n",
      "Epoch:  32 | Train loss: 0.058 | Val loss: 0.779 | Gen: ethay airway onditioningcay isway oringwlgway\n",
      "Epoch:  33 | Train loss: 0.047 | Val loss: 0.902 | Gen: ethay airway onditioniongcay isway orkingway\n",
      "Epoch:  34 | Train loss: 0.077 | Val loss: 0.933 | Gen: ethay airway onditioniongcay isway oringwringway\n",
      "Epoch:  35 | Train loss: 0.144 | Val loss: 1.134 | Gen: ehay aiwarway onditioningway isway orkingway\n",
      "Epoch:  36 | Train loss: 0.207 | Val loss: 0.957 | Gen: ethay aiway onditionioniongcy isway orkingway\n",
      "Epoch:  37 | Train loss: 0.170 | Val loss: 0.685 | Gen: ethay ariway onditioningcay isway orkingway\n",
      "Epoch:  38 | Train loss: 0.103 | Val loss: 0.641 | Gen: ethay arway onditioniongcay isway orkingway\n",
      "Epoch:  39 | Train loss: 0.067 | Val loss: 0.603 | Gen: ethay arway onditioningcay isway oringway\n",
      "Epoch:  40 | Train loss: 0.049 | Val loss: 0.656 | Gen: ethay arway onditiongcay isway orkingway\n",
      "Epoch:  41 | Train loss: 0.039 | Val loss: 0.647 | Gen: ethay airway onditiongcay isway orkingway\n",
      "Epoch:  42 | Train loss: 0.038 | Val loss: 0.655 | Gen: ethay airway onditioncay isway orkingway\n",
      "Epoch:  43 | Train loss: 0.048 | Val loss: 0.739 | Gen: ethay airway onditiongcay isway orkingway\n",
      "Epoch:  44 | Train loss: 0.053 | Val loss: 0.638 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  45 | Train loss: 0.032 | Val loss: 0.629 | Gen: ethay airway onditiongcay isway orkingway\n",
      "Epoch:  46 | Train loss: 0.022 | Val loss: 0.616 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  47 | Train loss: 0.020 | Val loss: 0.676 | Gen: ethay airway onditioningcay isway orikingway\n",
      "Epoch:  48 | Train loss: 0.021 | Val loss: 0.624 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  49 | Train loss: 0.018 | Val loss: 0.650 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Obtained lowest validation loss of: 0.6029220278828572\n",
      "source:\t\tthe air conditioning is working \n",
      "translated:\tethay airway onditioningcay isway orkingway\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = 'the air conditioning is working'\n",
    "\n",
    "trans64_args_s = AttrDict()\n",
    "args_dict = {\n",
    "              'data_file_name': 'pig_latin_small',\n",
    "              'cuda':True, \n",
    "              'nepochs':50, \n",
    "              'checkpoint_dir':\"checkpoints\", \n",
    "              'learning_rate':5e-4,\n",
    "              'early_stopping_patience': 20,\n",
    "              'lr_decay':0.99,\n",
    "              'batch_size': 64, \n",
    "              'hidden_size': 64, # Increased model size\n",
    "              'encoder_type': 'transformer',\n",
    "              'decoder_type': 'transformer', # options: rnn / rnn_attention / transformer\n",
    "              'num_transformer_layers': 3,\n",
    "}\n",
    "trans64_args_s.update(args_dict)\n",
    "print_opts(trans64_args_s)\n",
    "\n",
    "trans64_encoder_s, trans64_decoder_s, trans64_losses_s = train(trans64_args_s)\n",
    "\n",
    "translated = translate_sentence(TEST_SENTENCE, trans64_encoder_s, trans64_decoder_s, None, trans64_args_s)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dardK4RWvUWV",
    "outputId": "6fb3ccd6-8301-4832-eb7f-497e70e4aa93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                                      Opts                                      \n",
      "--------------------------------------------------------------------------------\n",
      "                         data_file_name: pig_latin_large                        \n",
      "                                   cuda: 1                                      \n",
      "                                nepochs: 50                                     \n",
      "                         checkpoint_dir: checkpoints                            \n",
      "                          learning_rate: 0.0005                                 \n",
      "                early_stopping_patience: 20                                     \n",
      "                               lr_decay: 0.99                                   \n",
      "                             batch_size: 512                                    \n",
      "                            hidden_size: 64                                     \n",
      "                           encoder_type: transformer                            \n",
      "                           decoder_type: transformer                            \n",
      "                 num_transformer_layers: 3                                      \n",
      "================================================================================\n",
      "================================================================================\n",
      "                                   Data Stats                                   \n",
      "--------------------------------------------------------------------------------\n",
      "('albuquerque', 'albuquerqueway')\n",
      "('ejaculation', 'ejaculationway')\n",
      "('kenwood', 'enwoodkay')\n",
      "('satire', 'atiresay')\n",
      "('rite', 'iteray')\n",
      "Num unique word pairs: 22402\n",
      "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
      "Vocab size: 29\n",
      "================================================================================\n",
      "Moved models to GPU!\n",
      "Epoch:   0 | Train loss: 2.373 | Val loss: 2.020 | Gen: --tttttttttttttttttt a-isay-iway intinay-intinay ssssssssssssssssssss -------------\n",
      "Epoch:   1 | Train loss: 1.693 | Val loss: 1.897 | Gen: etay-ay-ay-ay away-ay-ay ontinandnay-ay-ay-ay say-ay-ay-ay onay-ay-ay-ay-ay\n",
      "Epoch:   2 | Train loss: 1.472 | Val loss: 1.696 | Gen: etay-ay-ay-ay-ay-ay- away-ay-ay-ay ootioiontiongay-inay isay-isay-ay-y-y-ay- oway-ingay-y-y-y\n",
      "Epoch:   3 | Train loss: 1.316 | Val loss: 1.550 | Gen: ethay away oomiogay-ingay isay oway\n",
      "Epoch:   4 | Train loss: 1.188 | Val loss: 1.484 | Gen: ethay--------------- arawarawawawawawaway odingay-intingway isay oway-ingway\n",
      "Epoch:   5 | Train loss: 1.084 | Val loss: 1.415 | Gen: ethay iway onintindininay isay oway\n",
      "Epoch:   6 | Train loss: 0.990 | Val loss: 1.406 | Gen: ethay-ay-ay-y-y-y iraway ondingay-ingay isay oway-ingway\n",
      "Epoch:   7 | Train loss: 0.875 | Val loss: 1.223 | Gen: y-ethay iway ondigionay isay oway\n",
      "Epoch:   8 | Train loss: 0.762 | Val loss: 1.147 | Gen: ethay-ay iraway oningintiningway isay oway-ingway\n",
      "Epoch:   9 | Train loss: 0.683 | Val loss: 1.146 | Gen: thay-ay airway ondingitingway isay oway-ingway\n",
      "Epoch:  10 | Train loss: 0.641 | Val loss: 1.026 | Gen: ethay-ay arway ondingday-ingnway isay oway-ingway\n",
      "Epoch:  11 | Train loss: 0.600 | Val loss: 1.127 | Gen: thay iraway onditigionay isay owingay\n",
      "Epoch:  12 | Train loss: 0.590 | Val loss: 0.975 | Gen: tay-ay irway ontiniongray isway owingray\n",
      "Epoch:  13 | Train loss: 0.519 | Val loss: 0.911 | Gen: theway irway onditioningway isway owingray\n",
      "Epoch:  14 | Train loss: 0.466 | Val loss: 0.829 | Gen: ethay-ay irway oniditingnay isway orkingway\n",
      "Epoch:  15 | Train loss: 0.393 | Val loss: 0.776 | Gen: ethay awwway onditiniongway isway orkingway\n",
      "Epoch:  16 | Train loss: 0.346 | Val loss: 0.620 | Gen: ethay irway onditioningway isway orkingway\n",
      "Epoch:  17 | Train loss: 0.293 | Val loss: 0.668 | Gen: thay awwway onditiongway isway orkingway\n",
      "Epoch:  18 | Train loss: 0.287 | Val loss: 0.600 | Gen: ethay irway onditiongcay isway orkingway\n",
      "Epoch:  19 | Train loss: 0.253 | Val loss: 0.649 | Gen: theway airway onditioningway isway orkingway\n",
      "Epoch:  20 | Train loss: 0.260 | Val loss: 0.582 | Gen: ethay irway onditiongcay isway orkingway\n",
      "Epoch:  21 | Train loss: 0.225 | Val loss: 0.593 | Gen: thetay airway onditioningway isway okingway\n",
      "Epoch:  22 | Train loss: 0.214 | Val loss: 0.561 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  23 | Train loss: 0.186 | Val loss: 0.635 | Gen: thay airway onditioningnay isway orkingway\n",
      "Epoch:  24 | Train loss: 0.209 | Val loss: 0.856 | Gen: thetay iway otnitioncangcay isway otkingway\n",
      "Epoch:  25 | Train loss: 0.250 | Val loss: 0.982 | Gen: ethay awawwaway onintioningnay isway orkingngway\n",
      "Epoch:  26 | Train loss: 0.304 | Val loss: 0.916 | Gen: hetay airway onaitingcay isway okikingway\n",
      "Epoch:  27 | Train loss: 0.333 | Val loss: 0.563 | Gen: ethay airway ondintiongcay isway orkingway\n",
      "Epoch:  28 | Train loss: 0.216 | Val loss: 0.561 | Gen: ethay airway onditiongcay isway orkingway\n",
      "Epoch:  29 | Train loss: 0.166 | Val loss: 0.457 | Gen: ethay airway onditioncongnay isway orkingway\n",
      "Epoch:  30 | Train loss: 0.126 | Val loss: 0.318 | Gen: hetay airway onditioniongcay isway orkingway\n",
      "Epoch:  31 | Train loss: 0.096 | Val loss: 0.284 | Gen: ethay airway onditioniongcay isway orkingway\n",
      "Epoch:  32 | Train loss: 0.083 | Val loss: 0.256 | Gen: ehtay airway onditioniongcay isway orkingway\n",
      "Epoch:  33 | Train loss: 0.074 | Val loss: 0.269 | Gen: ethay airway onditioniongcay isway orkingway\n",
      "Epoch:  34 | Train loss: 0.065 | Val loss: 0.240 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  35 | Train loss: 0.057 | Val loss: 0.253 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  36 | Train loss: 0.057 | Val loss: 0.263 | Gen: ehtay airway onditioningcay isway orkingway\n",
      "Epoch:  37 | Train loss: 0.060 | Val loss: 0.270 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  38 | Train loss: 0.049 | Val loss: 0.247 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  39 | Train loss: 0.045 | Val loss: 0.286 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  40 | Train loss: 0.060 | Val loss: 0.477 | Gen: ehtay airway onditioningcay isway orkingway\n",
      "Epoch:  41 | Train loss: 0.159 | Val loss: 0.771 | Gen: ethay arwwway onditionigfigcay isway orkingwway\n",
      "Epoch:  42 | Train loss: 0.359 | Val loss: 0.700 | Gen: ethay airway ocditiongcay isway orkingway\n",
      "Epoch:  43 | Train loss: 0.197 | Val loss: 0.359 | Gen: ehtay airway onditioncangcay isway orkingway\n",
      "Epoch:  44 | Train loss: 0.100 | Val loss: 0.295 | Gen: ehtay airway onditioningcay isway orkingway\n",
      "Epoch:  45 | Train loss: 0.074 | Val loss: 0.248 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  46 | Train loss: 0.059 | Val loss: 0.221 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  47 | Train loss: 0.043 | Val loss: 0.212 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  48 | Train loss: 0.035 | Val loss: 0.207 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Epoch:  49 | Train loss: 0.031 | Val loss: 0.207 | Gen: ethay airway onditioningcay isway orkingway\n",
      "Obtained lowest validation loss of: 0.20658110524527729\n",
      "source:\t\tthe air conditioning is working \n",
      "translated:\tethay airway onditioningcay isway orkingway\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = 'the air conditioning is working'\n",
    "\n",
    "trans64_args_l = AttrDict()\n",
    "args_dict = {\n",
    "              'data_file_name': 'pig_latin_large', # Increased data set size\n",
    "              'cuda':True, \n",
    "              'nepochs':50,\n",
    "              'checkpoint_dir':\"checkpoints\", \n",
    "              'learning_rate':5e-4,\n",
    "              'early_stopping_patience': 20,\n",
    "              'lr_decay':0.99,\n",
    "              'batch_size': 512, \n",
    "              'hidden_size': 64, # Increased model size\n",
    "              'encoder_type': 'transformer',\n",
    "              'decoder_type': 'transformer', # options: rnn / rnn_attention / transformer\n",
    "              'num_transformer_layers': 3,\n",
    "}\n",
    "trans64_args_l.update(args_dict)\n",
    "print_opts(trans64_args_l)\n",
    "\n",
    "trans64_encoder_l, trans64_decoder_l, trans64_losses_l = train(trans64_args_l)\n",
    "\n",
    "translated = translate_sentence(TEST_SENTENCE, trans64_encoder_l, trans64_decoder_l, None, trans64_args_l)\n",
    "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSSyiG39vVlN"
   },
   "source": [
    "The following cell generates two loss plots. In the first plot, we compare the effects of increasing dataset size. In the second plot, we compare the effects of increasing model size. Include both plots in your report, and include your analysis of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Ql0pxrEvVP6",
    "outputId": "9021b1a2-c516-450f-a9e4-2185a562a8cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_loss_comparison_by_dataset(trans32_losses_s, trans32_losses_l, trans64_losses_s, trans64_losses_l, trans32_args_s, trans32_args_l, trans64_args_s, trans64_args_l, 'trans_by_dataset')\n",
    "save_loss_comparison_by_hidden(trans32_losses_s, trans32_losses_l, trans64_losses_s, trans64_losses_l, trans32_args_s, trans32_args_l, trans64_args_s, trans64_args_l, 'trans_by_hidden')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBnBXRG8mvcn"
   },
   "source": [
    "# Optional: Attention Visualizations\n",
    "\n",
    "One of the benefits of using attention is that it allows us to gain insight into the inner workings of the model.\n",
    "\n",
    "By visualizing the attention weights generated for the input tokens in each decoder step, we can see where the model focuses while producing each output token.\n",
    "\n",
    "The code in this section loads the model you trained from the previous section and uses it to translate a given set of words: it prints the translations and display heatmaps to show how attention is used at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqEC0vN9mvpV"
   },
   "source": [
    "## Step 1: Visualize Attention Masks\n",
    "Play around with visualizing attention maps generated by the previous two models you've trained. Inspect visualizations in one success and one failure case for both models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "id": "Dkfz-u-MtudL",
    "outputId": "53500e13-4e3a-49d0-b338-788b84986e7c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-5075212dbc3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mTEST_WORD_ATTN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'street'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvisualize_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_WORD_ATTN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_attn_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_attn_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "TEST_WORD_ATTN = 'street'\n",
    "visualize_attention(TEST_WORD_ATTN, rnn_attn_encoder, rnn_attn_decoder, None, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ssa7g35zt2yj"
   },
   "outputs": [],
   "source": [
    "TEST_WORD_ATTN = 'street'\n",
    "visualize_attention(TEST_WORD_ATTN, transformer_encoder, transformer_decoder, None, args, )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4BIpGwANoQOg",
    "pbvpn4MaV0I1",
    "bRWfRdmVVjUl",
    "0yh08KhgnA30",
    "ecEq4TP2lZ4Z",
    "RWwA6OGqlaTq",
    "AJSafHSAmu_w",
    "73_p8d5EmvOJ",
    "vYPae08Io1Fi",
    "9tcpUFKqo2Oi",
    "z1hDi020rT36",
    "MBnBXRG8mvcn"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
